{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we will go through a typical text mining pipeline. Our goal is to train a machine learning model that classifies texts scraped from company website into two classes: \n",
    "- **0**: Text from a non-software company website.\n",
    "- **1**: Text from a software company website.\n",
    "\n",
    "### Steps:\n",
    "1. Load a labelled and an unlabelled dataset.\n",
    "2. Preprocess the texts.\n",
    "3. Vectorize the texts.\n",
    "4. Split the labelled dataset into a training set and a test set.\n",
    "5. Train a logit regression classifier.\n",
    "6. Use the trained logit regression classifier to predict the missing labels in the unlabelled dataset.\n",
    "7. Calculate text similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with two different datasets: a labelled dataset and an unlabelled one. For the observations in the labelled dataset, we know whether the texts are from a software company website (\"class_1\" in the figure) or not (\"class_2\"). For the observations in the unlabelled dataset, we do not have this information and we want to **predict the missing classes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"labelled_data.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load \"labelled_data.txt\", a text file with \"labelled\" website data. \"Labelled\" means that each observation is already categorized in a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in a table format with 4 columns:\n",
    "- \"ID\": unique identifiers for each observation\n",
    "- \"url\" the website address from where text was downloaded\n",
    "- \"text\": the downloaded website text\n",
    "- \"software\": the label which tells us whether a website is from a software company (\"1\") or not (\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://autzen-reimers.de</td>\n",
       "      <td>Seite: « 1 / 0 » « 1 / 0 »AUTZEN &amp; REIMERSARCH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://ibos-goerlitz.de/</td>\n",
       "      <td>Das Ingenieurbüro IBOS GmbH wurde am 17.09.199...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://kaizhong-vogt.de/</td>\n",
       "      <td>capanne.gittinger.de</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://baecker-holland.de/</td>\n",
       "      <td>Klicken Sie hier um zu unserem Kon­takt­for­mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.vbhnr.de/privatkunden.html</td>\n",
       "      <td>Um Ihnen eine bessere Nutzung unserer Seite zu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     url  \\\n",
       "0   0                http://autzen-reimers.de   \n",
       "1   1               https://ibos-goerlitz.de/   \n",
       "2   2               https://kaizhong-vogt.de/   \n",
       "3   3             https://baecker-holland.de/   \n",
       "4   4  https://www.vbhnr.de/privatkunden.html   \n",
       "\n",
       "                                                text  software  \n",
       "0  Seite: « 1 / 0 » « 1 / 0 »AUTZEN & REIMERSARCH...         0  \n",
       "1  Das Ingenieurbüro IBOS GmbH wurde am 17.09.199...         0  \n",
       "2                               capanne.gittinger.de         0  \n",
       "3  Klicken Sie hier um zu unserem Kon­takt­for­mu...         0  \n",
       "4  Um Ihnen eine bessere Nutzung unserer Seite zu...         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data = pd.read_csv(\"labelled_data.txt\", sep=\"\\t\", encoding=\"utf-8\", error_bad_lines=False)\n",
    "labelled_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2000 rows (observations) and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the website of a random software company in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"200\"\n",
       "            src=\"http://heinke-automation.de\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e44917f348>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "random_software_url = labelled_data[labelled_data[\"software\"] == 1].sample(1)[\"url\"].values[0]\n",
    "\n",
    "display(IFrame(random_software_url, width=800, height=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a look at the \"software\" column and check out how many \"1\"s (software companies) and \"0\"s (other company types) we have in our data. \n",
    "\n",
    "For that we select the \"software\" column and then use pandas ```value_counts()``` method to count the ones and zeros in that column. As we can see, 1716 \"0\"s and 284 \"1\"s are in the dataset, which means that we have many more non-software firms than software firms in our labelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1716\n",
       "1     284\n",
       "Name: software, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[\"software\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at our text data.\n",
    "\n",
    "First, we may want to see how large our texts are. We can do so by selecting the \"text\" column and use ```apply(len)``` on it. This will return us the lenght (number of characters) of each text in our dataset. By adding pandas ```describe()``` method, we will get some descriptive statistics telling us that the mean number number of characters (2558.8) per website text, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2000.000000\n",
       "mean       2558.813500\n",
       "std        5144.796468\n",
       "min           1.000000\n",
       "25%         703.000000\n",
       "50%        1472.500000\n",
       "75%        2788.500000\n",
       "max      135504.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[\"text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD3CAYAAADhaQjCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWYElEQVR4nO3df0zU9+HH8dcBBSM/RLK0G1Y3mNpqGlKR4UwQu1+lzbSzF+whLdq4Lba1KFYdFAralWqdkfQHsWqytIl09mSQrI3bukq1CK3Y2R9G6trpnF2BWi1scher530+3z++4VamdW/qfbhzPB+JyfG+930+Lwzhxfvzuc/nXLZt2wIAwEBMpAMAAK4elAYAwBilAQAwRmkAAIxRGgAAY3GRDjBUM2bM0Lhx4yIdAwCuKl1dXero6Lji7Vx1pTFu3Dg1NzdHOgYAXFXcbndYtsPhKQCAMUoDAGCM0gAAGKM0AADGKA0AgDFKAwBgjNIAABijNAAAxigNAICxEVUanweCl3wMADBz1d1G5EqMuiZW36rYJUn6+xM/jnAaALj6jKiVBgDgylAaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGOUBgDAGKUBADBGaQAAjFEaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGOUBgDAGKUBADBGaQAAjFEaAABjlAYAwFicExsNBAKqqKhQV1eXYmJi9NhjjykuLk4VFRVyuVyaNGmS1qxZo5iYGNXX12vv3r2Ki4tTZWWlsrKynIgEAAgDR0rj9ddf14ULF/Tiiy+qvb1dTz75pAKBgMrKyjRjxgzV1NSopaVF6enpOnDggBobG9XT06PS0lI1NTU5EQkAEAaOlEZGRoaCwaAsy5LP51NcXJzeffdd5ebmSpLy8/PV3t6ujIwM5eXlyeVyKT09XcFgUL29vUpLSxu0Pa/XK6/XK0nq6+tzIjIAwIAjpTF69Gh1dXXp9ttvV19fn7Zs2aK33npLLpdLkpSYmKj+/n75fD6lpqaGXjcw/p+l4fF45PF4JElut9uJyAAAA46UxvPPP6+8vDytXLlSPT09WrRokQKBQOh5v9+vlJQUJSUlye/3DxpPTk52IhIAIAwcefdUSkpK6Jf/mDFjdOHCBU2dOlUdHR2SpNbWVuXk5Cg7O1ttbW2yLEvd3d2yLOuiVQYAIHo4stK49957VVlZqeLiYgUCAa1YsUI33XSTqqurVVdXp8zMTBUUFCg2NlY5OTnyeDyyLEs1NTVOxAEAhIkjpZGYmKinnnrqovGGhoaLxkpLS1VaWupEDABAmHFxHwDAGKUBADBGaQAAjFEaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGOUBgDAGKUBADBGaQAAjFEaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGOUBgDAGKUBADBGaQAAjFEaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGNxTm1469ateu211xQIBLRgwQLl5uaqoqJCLpdLkyZN0po1axQTE6P6+nrt3btXcXFxqqysVFZWllORAABXyJGVRkdHh9555x3t2LFD27dv1yeffKL169errKxMv/nNb2TbtlpaWtTZ2akDBw6osbFRdXV1evTRR52IAwAIE0dWGm1tbZo8ebKWLl0qn8+nX/ziF9q5c6dyc3MlSfn5+Wpvb1dGRoby8vLkcrmUnp6uYDCo3t5epaWlDdqe1+uV1+uVJPX19TkRGQBgwJHS6OvrU3d3t7Zs2aKPP/5Y999/v2zblsvlkiQlJiaqv79fPp9PqampodcNjP9naXg8Hnk8HkmS2+12IjIAwIDR4alTp04NaaOpqanKy8tTfHy8MjMzlZCQoP7+/tDzfr9fKSkpSkpKkt/vHzSenJw8pH0BAIaPUWksW7ZMS5cu1Z49e2RZ1n+dP336dO3bt0+2bevkyZM6e/asZs6cqY6ODklSa2urcnJylJ2drba2NlmWpe7ublmWddEqAwAQPYwOT+3YsUNHjx5VU1OTnn32Wc2cOVOFhYUaP378Jed/73vf01tvvaXCwkLZtq2amhpdf/31qq6uVl1dnTIzM1VQUKDY2Fjl5OTI4/HIsizV1NSE9ZsDAISXy7Zt22Rif3+/Xn75Zf3xj39UYmKibNvWxIkTtWrVKqczDuJ2u9Xc3PyVX/+til2SpL8/8eNwRQKAqHelvzsHGK00li9frr/+9a+64447tHHjRl133XWhEACAkcOoNO666y7dfPPNSkxM1Keffhoa37Fjh2PBAADRx+hE+Ntvv62tW7dKkmpra7Vt2zZJUkJCgnPJAABRx6g09uzZo4ceekiS9PTTT+u1115zNBQAIDoZlYbL5dL58+clSYFAQIbnzgEA/2OMzmkUFRVp7ty5mjx5sv72t7/pZz/7mdO5AABRyKg05s+frx/84Af6xz/+ofHjx3MBHgCMUEalceTIEXm9Xp07dy40tn79esdCDYfPA0GNuib2oscAgC9nVBoVFRW655579PWvf93pPMNm1DWxXOgHAENkVBpf+9rXNH/+fKezAACinFFpjBs3Ttu2bdOUKVNCtzfPy8tzNBgAIPoYlUYgENDx48d1/Pjx0BilAQAjj1FprF+/XsePH9dHH32kG264Qddee63TuQAAUcioNBoaGvTqq6/qX//6l+68806dOHGC25gDwAhkdEX4rl279Nxzzyk5OVmLFi3Se++953QuAEAUMiqNgc/3HjgJHh8f72goAEB0Mjo8NWfOHN19993q7u7Wz3/+c/3whz90OhcAIAoZlcY999yjmTNn6sMPP1RGRoZuvPFGp3MBAKKQUWnU19eHHh87dky7d+/Wgw8+6FgoAEB0Mr4iXPr/cxvvv/++LMtyNBQAIDoZ3xr9i7g1OgCMTEal8cUrwU+dOqXu7m7HAgEAopdRaXzxQr6EhASVl5c7FggAEL2MSmP79u1O5wAAXAWMSuOOO+6Q3+9XQkJC6IOYBi74a2lpcTQgACB6GJXGtGnTNG/ePE2bNk0ffPCBfv3rX6u2ttbpbACAKGNUGseOHdO0adMkSTfccIN6enq4lQgAjEBGpZGcnKwnn3xSWVlZ+vOf/6z09HSncwEAopDRDQs3bdqkpKQk7du3TxMmTNDjjz/udC4AQBQyKo2EhASNGTNGqampysjI0JkzZ5zOBQCIQkalUVNTo+7ubr3xxhvy+/1cpwEAI5RRaXz00Udavny54uPj9f3vf1/9/f1O5wIARCGj0ggGg+rt7ZXL5ZLP51NMjNHLAAD/Y4zePbVixQotWLBAp06dksfjUVVVldO5AABRyKg0enp69Morr6i3t1djx44NfewrAGBkMTrOtHPnTklSWlqacWF89tlnmj17to4dO6YTJ05owYIFKi4u1po1a0Kfx1FfX6/CwkIVFRXp0KFDX/FbAAAMF6OVxvnz5zVv3jxlZGSEzmds2rTpS+cHAgHV1NRo1KhRkqT169errKxMM2bMUE1NjVpaWpSenq4DBw6osbFRPT09Ki0tVVNTUxi+JQCAUy5bGps3b9YDDzygVatW6eTJk7ruuuuMNrphwwYVFRVp27ZtkqTOzk7l5uZKkvLz89Xe3q6MjAzl5eXJ5XIpPT09dLI9LS3tCr8lAIBTLnt4av/+/ZKk3NxcNTY2Kjc3N/TvyzQ3NystLU2zZs0KjQ3cEVeSEhMT1d/fL5/Pp6SkpNCcgfFL8Xq9crvdcrvd6uvrM//uAABhddmVhm3bl3x8OU1NTXK5XHrzzTd15MgRlZeXq7e3N/S83+9XSkqKkpKS5Pf7B40nJydfcpsej0cej0eS5Ha7jXIAAMLvsiuNL570Nj0B/sILL6ihoUHbt2/XlClTtGHDBuXn56ujo0OS1NraqpycHGVnZ6utrU2WZam7u1uWZXFoCgCi3GVXGp2dnSoqKpJt2zp69Gjoscvl0osvvmi8k/LyclVXV6uurk6ZmZkqKChQbGyscnJy5PF4ZFnWoI+UBQBEp8uWxksvvXRFG//ix8Q2NDRc9HxpaalKS0uvaB8AgOFz2dIYN27ccOUAAFwFuIkUAMAYpQEAMEZpAACMURoAAGOUBgDAGKUBADBGaQAAjFEaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGOUBgDAGKUBADBGaQAAjFEaAABjlAYAwBilAQAwRmkAAIxRGgAAY5QGAMAYpQEAMEZpAACMURoAAGOUhqTPA8FLPgYADBYX6QDRYNQ1sfpWxS5J0t+f+HGE0wBA9GKlAQAwRmkAAIxRGgAAY5QGAMAYpQEAMBb2d08FAgFVVlaqq6tL58+f1/3336+JEyeqoqJCLpdLkyZN0po1axQTE6P6+nrt3btXcXFxqqysVFZWVrjjAADCKOyl8dJLLyk1NVUbN27UP//5T82bN0833nijysrKNGPGDNXU1KilpUXp6ek6cOCAGhsb1dPTo9LSUjU1NYU7DgAgjMJeGrfddpsKCgokSbZtKzY2Vp2dncrNzZUk5efnq729XRkZGcrLy5PL5VJ6erqCwaB6e3uVlpYW7kgAgDAJ+zmNxMREJSUlyefzadmyZSorK5Nt23K5XKHn+/v75fP5lJSUNOh1/f39l9ym1+uV2+2W2+1WX19fuCMDAAw5ciK8p6dHCxcu1E9+8hPNnTtXMTH/3o3f71dKSoqSkpLk9/sHjScnJ19yex6PR83NzWpubtbYsWOdiAwAMBD20jh9+rQWL16s1atXq7CwUJI0depUdXR0SJJaW1uVk5Oj7OxstbW1ybIsdXd3y7IsDk0BQJQL+zmNLVu26MyZM9q8ebM2b94sSaqqqlJtba3q6uqUmZmpgoICxcbGKicnRx6PR5ZlqaamJtxRAABhFvbSeOSRR/TII49cNN7Q0HDRWGlpqUpLS8MdAQDgEC7uAwAYozQAAMYoDQCAMUoDAGCM0gAAGKM0AADGKA0AgDFKAwBgjNIAABijNAAAxigNAIAxSgMAYIzSAAAYozQAAMYoDQCAMUoDAGCM0vgPnweCl3wMAHDgk/uudqOuidW3KnZJkv7+xI8jnAYAogsrDQCAMUoDAGCM0gAAGKM0AADGKA0AgDFKAwBgjNIAABijNAAAxigNAIAxSuMyuKUIAAzGbUQug1uKAMBgrDQAAMYoDQCAMUoDAGCM0jDESXEA4ES4MU6KAwArDQDAEFAaXwGHqgCMVBE/PGVZltauXasPPvhA8fHxqq2t1Te/+c1Ix7qsLx6q+stjt4XGPw8ENeqa2EjFAgDHRXylsXv3bp0/f15er1crV67UE088EelIQzJQIAMlMuByK5ArWamwygEQSREvjYMHD2rWrFmSpJtvvlmHDx+OcKKvzrRAvkrRDOW1JsUy1PKhrABIksu2bTuSAaqqqnTrrbdq9uzZkqRbbrlFu3fvVlzcv4+ceb1eeb1eSdLx48eVkZHxlfbV19ensWPHXnnoYUTm4UHm4UHm4XGpzF1dXero6LjyjdsRtm7dOnvXrl2hr2fNmuXYvu68807Htu0UMg8PMg8PMg8PJzNH/PBUdna2WltbJUnvvvuuJk+eHOFEAIAvE/F3T/3oRz9Se3u7ioqKZNu21q1bF+lIAIAvEfHSiImJ0S9/+cth2ZfH4xmW/YQTmYcHmYcHmYeHk5kjfiIcAHD1iPg5DQDA1YPSAAAYGxGlYVmWampq5PF4VFJSohMnTgx7hkAgoNWrV6u4uFiFhYVqaWnRiRMntGDBAhUXF2vNmjWyLEuSVF9fr8LCQhUVFenQoUOSNKS54fbZZ59p9uzZOnbs2FWReevWrfJ4PHK73WpsbIz6zIFAQCtXrlRRUZGKi4uj/v/5vffeU0lJyZD3HY654ch85MgRFRcXq6SkRD/96U91+vRpSdLOnTvldrt11113ac+ePZKk3t5eLV68WMXFxSorK9PZs2eHPDccmQe8/PLLg85XRCSzY2/mjSKvvPKKXV5ebtu2bb/zzjv2fffdN+wZfvvb39q1tbW2bdt2X1+fPXv2bHvJkiX2/v37bdu27erqavtPf/qTffjwYbukpMS2LMvu6uqy3W63bdv2kOaG0/nz5+0HHnjAvvXWW+2jR49Gfeb9+/fbS5YssYPBoO3z+eynn3466jO/+uqr9rJly2zbtu22tjb7wQcfjNrM27Zts+fMmWPPnz9/yPu+0rnhynz33Xfb77//vm3btr1jxw573bp19qeffmrPmTPHPnfunH3mzJnQ48cee8xuamqybdu2t27daj/33HNDmhuuzLZt252dnfbChQtDY5HKPCJWGtFwq5LbbrtNy5cvlyTZtq3Y2Fh1dnYqNzdXkpSfn6833nhDBw8eVF5enlwul9LT0xUMBtXb2zukueG0YcMGFRUV6dprr5WkqM/c1tamyZMna+nSpbrvvvt0yy23RH3mjIwMBYNBWZYln8+nuLi4qM08YcIEPfPMM6Gvncp5qbnhylxXV6cpU6ZIkoLBoBISEnTo0CFNmzZN8fHxSk5O1oQJE/SXv/xl0O+OgRxDmRuuzH19faqrq1NlZWVoLFKZR0Rp+Hw+JSUlhb6OjY3VhQsXhjVDYmKikpKS5PP5tGzZMpWVlcm2bblcrtDz/f39F2UdGB/K3HBpbm5WWlpa6IdKUtRn7uvr0+HDh/XUU0/p0Ucf1apVq6I+8+jRo9XV1aXbb79d1dXVKikpidrMBQUFg27x41TOS80NV+aBP4DefvttNTQ06N5775XP51NycvKgHD6fb9D4FzObzg1H5mAwqKqqKj388MNKTEwMzYlU5ohfpzEckpKS5Pf7Q19bljXoh2i49PT0aOnSpSouLtbcuXO1cePG0HN+v18pKSkXZfX7/UpOTlZMTIzx3HBpamqSy+XSm2++qSNHjqi8vHzQX6vRmDk1NVWZmZmKj49XZmamEhIS9Mknn0R15ueff155eXlauXKlenp6tGjRIgUCgajOPGAo+77SueH0+9//Xs8++6y2bdumtLS0L80xMD5q1Kj/mvlSc8Ohs7NTJ06c0Nq1a3Xu3DkdPXpUjz/+uL773e9GJPOIWGlEw61KTp8+rcWLF2v16tUqLCyUJE2dOjV0A7HW1lbl5OQoOztbbW1tsixL3d3dsixLaWlpQ5obLi+88IIaGhq0fft2TZkyRRs2bFB+fn5UZ54+fbr27dsn27Z18uRJnT17VjNnzozqzCkpKaFf6GPGjNGFCxei/mdjgFM5LzU3XH73u9+Ffq7Hjx8vScrKytLBgwd17tw59ff369ixY5o8ebKys7P1+uuvh3JMnz59SHPDISsrS7t27dL27dtVV1eniRMnqqqqKmKZR8TFfQMf9PThhx+GblXy7W9/e1gz1NbW6g9/+IMyMzNDY1VVVaqtrVUgEFBmZqZqa2sVGxurZ555Rq2trbIsSw8//LBycnJ0/PhxVVdXG811QklJidauXauYmBjjHJHK/Ktf/UodHR2ybVsrVqzQ9ddfH9WZ/X6/KisrderUKQUCAS1cuFA33XRT1Gb++OOP9dBDD2nnzp1D2nc45l5p5h07dmjmzJn6xje+Efqr+jvf+Y6WLVumnTt3yuv1yrZtLVmyRAUFBTp9+rTKy8vl9/s1duxYbdq0SaNHjx7S3HD8P3/ZWCQyj4jSAACEx4g4PAUACA9KAwBgjNIAABijNAAAxigNAIAxSgMAYIzSAAAY+z8GYnBzdUJCxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelled_data[\"text\"].apply(len).plot(kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load unlabelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the same procedure as above to load a dataset with \"unlabelled\" data. In our case this means that the dataset contains website data without the \"software\" label, so we don't know whether the companies are software firms or not...but we will know soon using machine learning!\n",
    "\n",
    "The ```shape``` method tells us that we have 937 observations and three columns (compared to the labelled dataset, we are missing the \"software\" column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://wimatec-mattes.de</td>\n",
       "      <td>Dieses Motto begleitet uns täglich bei der Arb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.jacobi.net/</td>\n",
       "      <td>Reactivated carbons for water and vapour treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.basf.com/de.html</td>\n",
       "      <td>Cookies helfen uns bei der Bereitstellung unse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://gjb.de</td>\n",
       "      <td>Diese Seite verwendet Frames. Frames werden vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.roda-swiss.de/</td>\n",
       "      <td>| Transparenz und Ihre Privatsphäre sind uns w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           url  \\\n",
       "0   0      http://wimatec-mattes.de   \n",
       "1   1       https://www.jacobi.net/   \n",
       "2   2  https://www.basf.com/de.html   \n",
       "3   3                 http://gjb.de   \n",
       "4   4    https://www.roda-swiss.de/   \n",
       "\n",
       "                                                text  \n",
       "0  Dieses Motto begleitet uns täglich bei der Arb...  \n",
       "1  Reactivated carbons for water and vapour treat...  \n",
       "2  Cookies helfen uns bei der Bereitstellung unse...  \n",
       "3  Diese Seite verwendet Frames. Frames werden vo...  \n",
       "4  | Transparenz und Ihre Privatsphäre sind uns w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data = pd.read_csv(\"unlabelled_data.txt\", sep=\"\\t\", encoding=\"utf-8\", error_bad_lines=False)\n",
    "print(unlabelled_data.shape)\n",
    "unlabelled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      937.000000\n",
       "mean      2524.799360\n",
       "std       4250.109905\n",
       "min          1.000000\n",
       "25%        711.000000\n",
       "50%       1491.000000\n",
       "75%       2732.000000\n",
       "max      48516.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data[\"text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding short texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, there are quite some websites with texts that are shorter than 500 characters and some even had only a single character. Let's exclude them. After that we have 1,649 observations left in our labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before:  (2000, 4)\n",
      "Dataframe shape after:  (1649, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe shape before: \", labelled_data.shape)\n",
    "labelled_data = labelled_data[labelled_data[\"text\"].apply(len) > 499]\n",
    "print(\"Dataframe shape after: \", labelled_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure should also be applied to the unlabelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before:  (937, 3)\n",
      "Dataframe shape after:  (772, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe shape before: \", unlabelled_data.shape)\n",
    "unlabelled_data = unlabelled_data[unlabelled_data[\"text\"].apply(len) > 499]\n",
    "print(\"Dataframe shape after: \", unlabelled_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the texts in our dataset are exactly as they were downloaded from the company websites.\n",
    "\n",
    "Let's have a look at an example by displaying observation with ```ID == 1928```. We also alter a pandas option to display us more of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>http://www.brandt-transporte.com/</td>\n",
       "      <td>| My Cart Copyright © 2018 . Powered byNew Products For October Monthly Specials For OctoberCategories Shop by Category Customer Services Quick Links Social MediaAMI Alexandre Mattiussi Amiri ANYA HINDMARCH Belstaff Diemme Issey Miyake Scott Tods Topo athletic Zone3 $124.52 $62.26 Save: 50% off $145.92 $72.96 Save: 50% off $125.17 $62.59 Save: 50% off $149.18 $74.59 Save: 50% off $145.29 $72.64 Save: 50% off $145.29 $72.64 Save: 50% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $592.66 $151.41 Save: 74% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                url  \\\n",
       "1928  1928  http://www.brandt-transporte.com/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "1928  | My Cart Copyright © 2018 . Powered byNew Products For October Monthly Specials For OctoberCategories Shop by Category Customer Services Quick Links Social MediaAMI Alexandre Mattiussi Amiri ANYA HINDMARCH Belstaff Diemme Issey Miyake Scott Tods Topo athletic Zone3 $124.52 $62.26 Save: 50% off $145.92 $72.96 Save: 50% off $125.17 $62.59 Save: 50% off $149.18 $74.59 Save: 50% off $145.29 $72.64 Save: 50% off $145.29 $72.64 Save: 50% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $592.66 $151.41 Save: 74% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off   \n",
       "\n",
       "      software  \n",
       "1928         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "labelled_data[labelled_data[\"ID\"] == 1928]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there can be quiet a lot of special characters (e.g. \"%\" or \"€\") and numbers in the text which we may want to exclude from the further analysis. We also may want to standardise all characters to lowercase, such that \"Software\" and \"software\" are recognized as the same words by the computer.\n",
    "\n",
    "We will import a Python's \"regular expression\" package and apply the ```sub(\"FILTER\", \"REPLACE_STRING\")``` function to the text column of our labelled dataset. We submit the ```sub()``` function with a so-called regular expression telling it to delete all characters in the text that are not part of this list of characters: *\"abcdefghijklmnopqrstuvwxyzäöüß&. \"*. \n",
    "\n",
    "The method ```lower()``` will cast all characters to lowercase, while ```strip()``` will delete \"trailing\" whitespaces (e.g. \"last word ____\" --> \"last word\").\n",
    "\n",
    "We will replace the original text in the \"text\" column with the result of this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "labelled_data[\"text\"] = labelled_data[\"text\"].apply(lambda x: re.sub(\"[^abcdefghijklmnopqrstuvwxyzäöüß& ']\", \"\", str(x).lower()).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this step changed the text of our example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>http://www.brandt-transporte.com/</td>\n",
       "      <td>my cart copyright    powered bynew products for october monthly specials for octobercategories shop by category customer services quick links social mediaami alexandre mattiussi amiri anya hindmarch belstaff diemme issey miyake scott tods topo athletic zone   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                url  \\\n",
       "1928  1928  http://www.brandt-transporte.com/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   text  \\\n",
       "1928  my cart copyright    powered bynew products for october monthly specials for octobercategories shop by category customer services quick links social mediaami alexandre mattiussi amiri anya hindmarch belstaff diemme issey miyake scott tods topo athletic zone   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   \n",
       "\n",
       "      software  \n",
       "1928         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[labelled_data[\"ID\"] == 1928]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Let's apply the same operation on the text column of the unlabelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data[\"text\"] = unlabelled_data[\"text\"].apply(lambda x: re.sub(\"[^abcdefghijklmnopqrstuvwxyzäöüß& ']\", \"\", str(x).lower()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://wimatec-mattes.de</td>\n",
       "      <td>dieses motto begleitet uns täglich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschleißfesten messern für erntemaschinen und mehr als erstausrüster haben wir uns seit unserer gründung  als partner der landmaschinenindustrie einen namen gemacht und wir können mehr unser portfolio umfasst das fertigen von schweißteilen kunden schätzen an uns qualität zuverlässigkeit service sowie schnelle verfügbarkeit diese garantieren wir mit unserem stets gut gefüllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erhält fördermittel der eu und des landes badenwürttemberg nur  unternehmen aus ganz badenwürttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde für das förderprogramm spitze auf dem land technologieführer für badenwürttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung für die erfolgreiche geschäftstätigkeit auf grundlage unserer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.jacobi.net/</td>\n",
       "      <td>reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.basf.com/de.html</td>\n",
       "      <td>cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erklären sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie öl und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterstützt die basf kunden und partner in mehr als  ländern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem überblick der basfgruppe erfahren sie mehr über den basfpalmdia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.roda-swiss.de/</td>\n",
       "      <td>transparenz und ihre privatsphäre sind uns wichtig warum cookies einfach weil sie helfen die website nutzbar zu machen ihre browsererfahrung zu verbessern und um mit social media zu interagieren klicken sie auf akzeptieren und fortfahren um die cookies zu akzeptieren und mit der seitennutzung fortzufahren datenschutzerklärung wir freuen uns sehr über ihr interesse an unserem unternehmen datenschutz hat einen besonders hohen stellenwert für die geschäftsleitung der rodaswiss kunststofftechnik gmbh  eine nutzung der internetseiten der rodaswiss kunststofftechnik gmbh ist grundsätzlich ohne jede angabe personenbezogener daten möglich sofern eine betroffene person besondere services unseres unternehmens über unsere internetseite in anspruch nehmen möchte könnte jedoch eine verarbeitung personenbezogener daten erforderlich werden ist die verarbeitung personenbezogener daten erforderlich und besteht für eine solche verarbeitung keine gesetzliche grundlage holen wir generell eine einwilli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           url  \\\n",
       "0   0      http://wimatec-mattes.de   \n",
       "1   1       https://www.jacobi.net/   \n",
       "2   2  https://www.basf.com/de.html   \n",
       "4   4    https://www.roda-swiss.de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  dieses motto begleitet uns täglich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschleißfesten messern für erntemaschinen und mehr als erstausrüster haben wir uns seit unserer gründung  als partner der landmaschinenindustrie einen namen gemacht und wir können mehr unser portfolio umfasst das fertigen von schweißteilen kunden schätzen an uns qualität zuverlässigkeit service sowie schnelle verfügbarkeit diese garantieren wir mit unserem stets gut gefüllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erhält fördermittel der eu und des landes badenwürttemberg nur  unternehmen aus ganz badenwürttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde für das förderprogramm spitze auf dem land technologieführer für badenwürttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung für die erfolgreiche geschäftstätigkeit auf grundlage unserer ...  \n",
       "1  reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...  \n",
       "2  cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erklären sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie öl und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterstützt die basf kunden und partner in mehr als  ländern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem überblick der basfgruppe erfahren sie mehr über den basfpalmdia...  \n",
       "4  transparenz und ihre privatsphäre sind uns wichtig warum cookies einfach weil sie helfen die website nutzbar zu machen ihre browsererfahrung zu verbessern und um mit social media zu interagieren klicken sie auf akzeptieren und fortfahren um die cookies zu akzeptieren und mit der seitennutzung fortzufahren datenschutzerklärung wir freuen uns sehr über ihr interesse an unserem unternehmen datenschutz hat einen besonders hohen stellenwert für die geschäftsleitung der rodaswiss kunststofftechnik gmbh  eine nutzung der internetseiten der rodaswiss kunststofftechnik gmbh ist grundsätzlich ohne jede angabe personenbezogener daten möglich sofern eine betroffene person besondere services unseres unternehmens über unsere internetseite in anspruch nehmen möchte könnte jedoch eine verarbeitung personenbezogener daten erforderlich werden ist die verarbeitung personenbezogener daten erforderlich und besteht für eine solche verarbeitung keine gesetzliche grundlage holen wir generell eine einwilli...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning algorithms we will use require us to give numerical data to them. Raw text data as an input will not work! This means that we have to transfer our texts to some kind of numerical representation without loosing too much information. Transferring a text from a sequence of characters to a vector of numbers is called \"text vectorization\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"text_vectorization.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to vectorize texts, from fancy techniques like [word embeddings](!https://en.wikipedia.org/wiki/Word_embedding) and topic models like [latent dirichlet allocation (LDA)](!https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) to simple [word count models](!https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will keep it rather simple and use an approach called **TFIDF** ([term frequency–inverse document frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)).\n",
    "- **term frequency (TF)**: The number of times a term $t$ (word) appears in a document $d$ adjusted by the length of the document (number of all words $t'$ in document $d$).\n",
    "\n",
    "\\begin{equation*}\n",
    "TF(t, d) =   \\frac{f_t,_d}{\\sum{f_{t^\\prime},_d}}\n",
    "\\end{equation*}\n",
    "\n",
    "- **inverse document frequency (IDF)**: Counts the number of documents $n_t$ an individual term $t$ appears over all documents $N$.\n",
    "\\begin{equation*}\n",
    "IDF(t) =   log{\\frac{N}{1 + n_t}}\n",
    "\\end{equation*}\n",
    "\n",
    "- **term frequency-inverse document frequency (TFIDF)**: This step weights down common words like \"the\" and gives more weight to rare words like \"software\".\n",
    "\n",
    "\\begin{equation*}\n",
    "TFIDF(t, d) = TF(t, d) * IDF(t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use scikit-learn' [TFIDF Vectorizer](!https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to generate TFIDF vectors from our texts. Scikit-learn is the most popular machine learning package for Python and includes all kinds of ML algorithms from clustering to classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"500\"\n",
       "            src=\"https://scikit-learn.org/stable/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e44b5df508>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(IFrame(\"https://scikit-learn.org/stable/\", width=1200, height=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn (sklearn) should come pre-installed with Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\jan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\jan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\jan\\anaconda3\\lib\\site-packages (from scikit-learn) (0.14.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import sklearn's ```TfidfVectorizer``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating TFIDF vectors from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to initialize a TFIDF vectorizer. We pass the ```analyzer=\"word\"``` parameter to tell the function to analyze our texts at the level of words (rather than single characters, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to teach our vocabulary to the vectorizer. For that we can use the vectorizer's ```fit()``` method on our texts. In this step, the vectorizer also calculates the inverse document frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_vectorizer = vectorizer.fit(labelled_data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the fitted vectorizer's ```transform()``` method to transform any text document to a TFIDF vector.\n",
    "\n",
    "Let's transform the sentence \"dies ist ein Test\" and output the resulting vector using Python's ```print()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 64619)\t0.5875299196376147\n",
      "  (0, 34840)\t0.6433973414680338\n",
      "  (0, 34005)\t0.17430190314904576\n",
      "  (0, 16620)\t0.18250280547152156\n",
      "  (0, 14515)\t0.4209038216459064\n"
     ]
    }
   ],
   "source": [
    "example_tfidf = fitted_vectorizer.transform([\"dies ist ein test kaffee\"])\n",
    "print(example_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output you see is a so-called sparse matrix. In a sparse matrix, only non-zero elements are memorized and mapped using indexes. This actually saves A LOT of memory. In the example above, there are only four non-zero elements in the matrix and their coordinates/indexes are given in the left parantheses. The elements on the right hand side give you the corresponding TFIDF value for the word mapped by the coordinates.\n",
    "\n",
    "Let's have a look at the vocabulary the vectorizer learned from our data. We call the ```vocabulary_``` method on the fitted vectorizer to retrieve then full vocabulary and the use a ```for``` loop to print the first items in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('das', 13209)\n",
      "('ingenieurbüro', 32913)\n",
      "('ibos', 31714)\n",
      "('gmbh', 27194)\n",
      "('wurde', 74328)\n",
      "('am', 1890)\n",
      "('in', 32182)\n",
      "('görlitz', 28454)\n",
      "('gegründet', 24982)\n",
      "('unser', 67469)\n",
      "('handlungsschwerpunkt', 28901)\n"
     ]
    }
   ],
   "source": [
    "vocabulary = fitted_vectorizer.vocabulary_\n",
    "\n",
    "#little loop to print the first items in the vocabulary\n",
    "for count, item in enumerate(iter(vocabulary.items())):\n",
    "    print(item)\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the vocabulary index of a word directly by passing it the word we are looking for (this only works for words that were learned during the ```fit()``` and thus are in the vocabulary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64619"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how many words are in our vocabulary, actually? We can see that by calculating its length using Python's ```len()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76713"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are quiet a lot of words. It may be a good idea to shrink down our vocabulary a bit, especially because this will reduce both memory consumption and the required computational power when we start doing ML magic!\n",
    "\n",
    "A common approach to do so is to apply so-called popularity-based filtering. Hereby, we exclude very common and/or extremly uncommon words from our vocabulary. This can be achieved by passing the corresponding parameters to the vectorizer during fitting. \n",
    "\n",
    "Let's overwrite our vectorizer and create a new one which includes only those words that appear in a maximum (```max_df```) of 80% and a minimum (```min_df```) of 1% of the websites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', min_df=0.01, max_df=0.8)\n",
    "fitted_vectorizer = vectorizer.fit(labelled_data[\"text\"])\n",
    "vocabulary = fitted_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary should be way smaller now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2622"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have excluded super frequent words like \"der\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'der'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-f44d00c66d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"der\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'der'"
     ]
    }
   ],
   "source": [
    "vocabulary[\"der\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium common words like \"test\", should be still included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2151"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2151)\t0.5734361764823801\n",
      "  (0, 1906)\t0.6223030737158058\n",
      "  (0, 1610)\t0.29360905796470727\n",
      "  (0, 1208)\t0.1701207267147181\n",
      "  (0, 498)\t0.41080712672525793\n"
     ]
    }
   ],
   "source": [
    "example_tfidf = fitted_vectorizer.transform([\"dies ist der neue test satz\"])\n",
    "print(example_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split our labelled dataset into a **training set** and a **test set**. The training set will be used to train our machine learning model to predict the correct labels (classes) of our observations within the training set itself by looking at the corresponding texts. After the training, we will use the trained model to predict the labels of all the observations in the test set, which was not used for training. Based on the prediction performance in the test set, we can evaluate the prediction performance of our trained model.\n",
    "\n",
    "This two-step approach is used to make sure that the ML model does not simply memorize all the observations in the training data, but instead derives universal rules on how to distinguish the different classes. This universal ability is called **generalization** and is very desireable in machine learning. In contrast, the over-memorization of the training set and a model's resulting bad performance using other data is called **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"training_split.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **training** of a machine learning model describes the process of teaching the model how to achive a certain learning task. In the case of a classification tasks, we give the model a list of properties $X$ (**features** or **attributes**) that are used to calculate a predicted outcome (**label** or **class**) $\\hat{Y}$. We then compare the predicted outcome $\\hat{Y}$ to the true outcome $Y$ that we know because we have a labelled dataset. In our example, we would use the trained ML model to predict whether a text comes from a software company website ($\\hat{Y}$ = 1 or 0) and the compare our predictions against the true values of $Y$.\n",
    "\n",
    "The difference between the predicted and the true outcome is then used to calculate an **error**. We then start to **optimize** (**train**) the model by adjusting its internal numbers $W$ (**weights**) to minimize the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"training.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the features (attributes) of our observations are the texts as TFIDF vectors and our labels are the \"1\" and \"0\" classes in the \"software\" column. In another ML task, the attributes could be, for example, the properties/features of a house (location, size, number of rooms etc.) and the outcome we want to predict could be the house's selling price.\n",
    "\n",
    "So let's first shuffle our data and then create a list with our features $X$ and a list with the corresponding labels $Y$. For the features we select the text column from our labelled dataset and transform them to TFIDF vectors using our trained vactorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data = labelled_data.sample(frac=1.0, random_state=12)\n",
    "features = fitted_vectorizer.transform(labelled_data[\"text\"])\n",
    "labels = labelled_data[\"software\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber that we hat 1,649 observations in our labelled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first 1,250 observations for the training set. The remaining obseravtions will be assigned to the test set and put aside for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trainset = features[:1250]\n",
    "labels_trainset = labels[:1250]\n",
    "\n",
    "features_testset = features[1250:]\n",
    "labels_testset = labels[1250:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: In a real life ML task, you should train your tfidf vectorizer on the training dataset only and not the test set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Training a logit regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our first model. We will start with something basic: A [logistic regression classifier](https://en.wikipedia.org/wiki/Logistic_regression). This classifier is a pretty popular model for binary outcome variables. Again, we will use scikit-learn for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to initialize the logisitic regression. We pass it the parameter ```class_weight=\"balanced\"``` because we have a pretty unbalanced dataset (one class in way more frequent than the other). The \"balanced\" parameter will make sure that the model will pay more attention to the infrequent class (in our case the software = 1 class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_classifier = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the classifier using its ```fit()``` method and passing the features and corresponding labels of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_logit_classifier = logit_classifier.fit(features_trainset, labels_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just trained your first machine learning model! But how good is it at distinguishing the web texts of software firms from other firm types? \n",
    "\n",
    "Let's test that with an example sentence that we transfer to a TFIDF vector using our trained vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bauernhof_tfidf = fitted_vectorizer.transform([\"das ist ein bauernhof und wir bauen getreide an\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1208)\t0.279137030214422\n",
      "  (0, 564)\t0.2922704239296758\n",
      "  (0, 441)\t0.2944505058129105\n",
      "  (0, 206)\t0.8119552312781735\n",
      "  (0, 55)\t0.30114468231328534\n"
     ]
    }
   ],
   "source": [
    "print(bauernhof_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this TFIDF vector to our trained logit classifier and tell it to predict its label using the ```predict()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_logit_classifier.predict(bauernhof_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted label is \"0\" (aka \"not a software company\"). Awesome!\n",
    "\n",
    "We can also check out the probability for both classes by using the ```predict_proba()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67518489, 0.32481511]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_logit_classifier.predict_proba(bauernhof_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number above gives you the probability that the label is \"0\" while the second number is the probability that the label is \"1\". So the classifier is not too confident (about 61%) that the text comes from the website of a non-software company (**WARNING: Your results may differ!**).\n",
    "\n",
    "Let's try one more example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03145259, 0.96854741]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programmer_tfidf = fitted_vectorizer.transform([\"wir programmieren software\"])\n",
    "trained_logit_classifier.predict_proba(programmer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_logit_classifier.predict(programmer_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! In this example, the model is absolutely sure (97%) that the text comes from a sofware company.\n",
    "\n",
    "We should now test our trained classifier using the test set which we put aside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = trained_logit_classifier.predict(features_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now ```print()``` the predicted labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the true labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels_testset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and compare them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True False  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True False  True False  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True False  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False False  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True False  True  True  True False  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False  True  True  True  True  True  True  True  True False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True False  True False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True False  True  True False  True False\n",
      "  True  True  True  True  True False False  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels == labels_testset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow...at first glace that looks pretty convincing. It seems like most of the predicted labels match their true counterparts, but not all of them.\n",
    "\n",
    "Let's quantify the classifier's prediction performance by generating a scikit-learn **classification report**. The report contains several measures that allow us to evaluate the performance of our trained model in the test set:\n",
    "\n",
    "- **precision**: the fraction of observations that were predicted to have label $\\hat{y} = 1$ and that actually have the true label $y = 1$.\n",
    "- **recall**: the fraction of observations that have the true label $y = 1$ and that were predicted to have $\\hat{y} = 1$.\n",
    "- **f1-score**: a composite measure that combines both precision and recall.\n",
    "- **support**: simply the number of observations with this true label in the test set.\n",
    "\n",
    "<img src=\"classification_report.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       323\n",
      "           1       0.71      0.79      0.75        76\n",
      "\n",
      "    accuracy                           0.90       399\n",
      "   macro avg       0.83      0.86      0.84       399\n",
      "weighted avg       0.90      0.90      0.90       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels_testset, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad! As you can see, the classification report gives you precision, recall, f1-score, and support for both labels (\"1\" and \"0\"). We could summarize the report as follows:\n",
    "- 95% of the observations that were labeled \"0\" by the classifier actually have the true label \"0\". For label \"1\" this value is only 71%\n",
    "- 92% of the observations that have the true label \"0\" were also predicted to have have the label \"0\" by the classifier. For label \"1\" this value is only 75%.\n",
    "\n",
    "So if our goal was to identify most of the software firms in the unlabelled dataset (**true positives**) while limiting the number of non-software firms that are wrongly classified as software firm (**false positives**), we could say:\n",
    "\"7 of 10 firms that were predicted to be software firms are actually software firms and we are able to recover 8 of 10 software firms in the dataset\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we can create a new column with our predicted labels in our labelled dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data.loc[labelled_data.index[1250:], 'prediction'] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and have a look at a random observations that has been assigned the wrong class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1298</td>\n",
       "      <td>https://www.schienle.de/de/</td>\n",
       "      <td>proportionalmagnete für ng ng ng und ng ventile in ex und non ex ausführung wirtschaftlich attraktive antriebslösungen für ihre ventile spulen und hubmagnete mit weltweiten explosionsschutz zulassungen energieeffiziente hubmagnetlösungen für batteriebetriebene und mobile anwendungen am anfang steht ein problem für das eine lösung gesucht wird  am ende liefern wir einen maßgeschneiderten schienle magneten auf dieses einfache prinzip können unsere kunden und partner schon lange vertrauen von beginn an arbeiten vertrieb entwicklung und produktion mit unseren kunden eng zusammen wir sorgen für transparenz bei den projektschritten so dass alle beteiligten jederzeit auf dem aktuellen stand sind im fokus steht immer das termingerechte und wirtschaftliche ergebnis und somit die interessen unserer kunden bald ist es wieder soweit  vom    märz  findet in aachen  bereits zum  mal  das internationale fluidtechnische kolloquium stattproportionalmagnete für die hydraulik ventilmagnete weltmagnet...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                          url  \\\n",
       "1298  1298  https://www.schienle.de/de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "1298  proportionalmagnete für ng ng ng und ng ventile in ex und non ex ausführung wirtschaftlich attraktive antriebslösungen für ihre ventile spulen und hubmagnete mit weltweiten explosionsschutz zulassungen energieeffiziente hubmagnetlösungen für batteriebetriebene und mobile anwendungen am anfang steht ein problem für das eine lösung gesucht wird  am ende liefern wir einen maßgeschneiderten schienle magneten auf dieses einfache prinzip können unsere kunden und partner schon lange vertrauen von beginn an arbeiten vertrieb entwicklung und produktion mit unseren kunden eng zusammen wir sorgen für transparenz bei den projektschritten so dass alle beteiligten jederzeit auf dem aktuellen stand sind im fokus steht immer das termingerechte und wirtschaftliche ergebnis und somit die interessen unserer kunden bald ist es wieder soweit  vom    märz  findet in aachen  bereits zum  mal  das internationale fluidtechnische kolloquium stattproportionalmagnete für die hydraulik ventilmagnete weltmagnet...   \n",
       "\n",
       "      software  prediction  \n",
       "1298         0         1.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_prediction = labelled_data[(labelled_data[\"software\"] != labelled_data[\"prediction\"]) & (labelled_data[\"prediction\"].notnull())].sample(1)\n",
    "wrong_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"350\"\n",
       "            src=\"https://www.schienle.de/de/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e451eafe08>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(IFrame(wrong_prediction[\"url\"].values[0], width=1200, height=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final step, we create a new column \"software\" in our unlabelled dataset and predict the labels using our trained logit classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://wimatec-mattes.de</td>\n",
       "      <td>dieses motto begleitet uns täglich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschleißfesten messern für erntemaschinen und mehr als erstausrüster haben wir uns seit unserer gründung  als partner der landmaschinenindustrie einen namen gemacht und wir können mehr unser portfolio umfasst das fertigen von schweißteilen kunden schätzen an uns qualität zuverlässigkeit service sowie schnelle verfügbarkeit diese garantieren wir mit unserem stets gut gefüllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erhält fördermittel der eu und des landes badenwürttemberg nur  unternehmen aus ganz badenwürttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde für das förderprogramm spitze auf dem land technologieführer für badenwürttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung für die erfolgreiche geschäftstätigkeit auf grundlage unserer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.jacobi.net/</td>\n",
       "      <td>reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.basf.com/de.html</td>\n",
       "      <td>cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erklären sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie öl und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterstützt die basf kunden und partner in mehr als  ländern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem überblick der basfgruppe erfahren sie mehr über den basfpalmdia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           url  \\\n",
       "0   0      http://wimatec-mattes.de   \n",
       "1   1       https://www.jacobi.net/   \n",
       "2   2  https://www.basf.com/de.html   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  dieses motto begleitet uns täglich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschleißfesten messern für erntemaschinen und mehr als erstausrüster haben wir uns seit unserer gründung  als partner der landmaschinenindustrie einen namen gemacht und wir können mehr unser portfolio umfasst das fertigen von schweißteilen kunden schätzen an uns qualität zuverlässigkeit service sowie schnelle verfügbarkeit diese garantieren wir mit unserem stets gut gefüllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erhält fördermittel der eu und des landes badenwürttemberg nur  unternehmen aus ganz badenwürttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde für das förderprogramm spitze auf dem land technologieführer für badenwürttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung für die erfolgreiche geschäftstätigkeit auf grundlage unserer ...   \n",
       "1  reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...   \n",
       "2  cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erklären sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie öl und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterstützt die basf kunden und partner in mehr als  ländern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem überblick der basfgruppe erfahren sie mehr über den basfpalmdia...   \n",
       "\n",
       "   predicted_software  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data[\"predicted_software\"] = unlabelled_data[\"text\"].apply(lambda text: trained_logit_classifier.predict(fitted_vectorizer.transform([text]))[0])\n",
    "unlabelled_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    647\n",
       "1    125\n",
       "Name: predicted_software, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data[\"predicted_software\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>882</td>\n",
       "      <td>https://www.cab.de/de/kennzeichnung/</td>\n",
       "      <td>für eine bessere nutzererfahrung auf cabde in ihrem browser diese webseite verwendet cookies wenn sie diese webseite benutzen erklären sie sich mit der verwendung von cookies gemäß unserer einverstanden falls sie keine cookies zulassen möchten können sie diese funktion in ihrem browser deaktivieren hinweise dazu finden sie in unserer  haben sie fragen beratung und verkauf außer beschriftungslaser für den desktopeinsatz kompakte drucker mit vielen funktionen großer industriedrucker für den industrieeinsatz flexible drucker für die industrielle anwendung für den einbau in produktionslinien der extrabreite etikettendrucker a für paletten und fassetiketten insbesondere für sehr kleine etiketten oder schmale endlosmaterialien insbesondere für endlostextilmaterial für beidseitiges drucken für zweifarbiges drucken für automatisches drucken und etikettieren in fertigungslinien zweifarbig drucken und etikettieren in einem arbeitsgang flexible drucker für die industrielle anwendung für den e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                   url  \\\n",
       "882  882  https://www.cab.de/de/kennzeichnung/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "882  für eine bessere nutzererfahrung auf cabde in ihrem browser diese webseite verwendet cookies wenn sie diese webseite benutzen erklären sie sich mit der verwendung von cookies gemäß unserer einverstanden falls sie keine cookies zulassen möchten können sie diese funktion in ihrem browser deaktivieren hinweise dazu finden sie in unserer  haben sie fragen beratung und verkauf außer beschriftungslaser für den desktopeinsatz kompakte drucker mit vielen funktionen großer industriedrucker für den industrieeinsatz flexible drucker für die industrielle anwendung für den einbau in produktionslinien der extrabreite etikettendrucker a für paletten und fassetiketten insbesondere für sehr kleine etiketten oder schmale endlosmaterialien insbesondere für endlostextilmaterial für beidseitiges drucken für zweifarbiges drucken für automatisches drucken und etikettieren in fertigungslinien zweifarbig drucken und etikettieren in einem arbeitsgang flexible drucker für die industrielle anwendung für den e...   \n",
       "\n",
       "     predicted_software  \n",
       "882                   0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Calculating text similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing texts as vectors has another advantage: It allows us to easily calculate distances between pairs of texts. By calculating such pairwise distances, we are able to identify pairs of texts that are very similar (close) or dissimilar (distant) to each other. Calculating the distances between observations in our dataset can be understood as comparing the business models of the companies as they are described on their websites. Let's try this out and see whether we can find Geographic Information System (GIS) software companies in our unlabelled dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to retrain our TFIDF vectorizer on our unlabelled dataset without the popularity-based filtering. This makes sure that all the words (41,955) in the unlabelled dataset are included in the resulting vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42336"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word')\n",
    "trained_vectorizer = vectorizer.fit(unlabelled_data[\"text\"])\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a single TFIDF vector from a description of the company type we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tfidf = trained_vectorizer.transform([\"gis geographie geographische informationssysteme geodaten\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tfidf_2 = trained_vectorizer.transform([\"künstliche intelligenz artificial intelligence ai ki machine learning maschinelles lernen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17874)\t0.5365635470684603\n",
      "  (0, 14829)\t0.5532618101527164\n",
      "  (0, 14052)\t0.637182022175651\n"
     ]
    }
   ],
   "source": [
    "print(search_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the popular [**cosine similarity**](!https://www.machinelearningplus.com/nlp/cosine-similarity/) to calculate the similarity between our TFIDF vectors. Cosine similarity measures the similarity between vectors based on their orientation in the high-dimensional vector space. The smaller the angle between two documents, the more similar they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will use a function from scikit-learn [```cosine_similarity()```](!https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) to calculate the cosine similarity between our search TFIDF vectors and the TFIDF vectors representing the company website texts in our unlabelled dataset. We do so by applying the function to the text column and creating a new column \"similarity\" with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "unlabelled_data[\"similarity_gis\"] = unlabelled_data[\"text\"].apply(lambda x: cosine_similarity(search_tfidf, trained_vectorizer.transform([x])).tolist()[0][0])\n",
    "\n",
    "unlabelled_data[\"similarity_ai\"] = unlabelled_data[\"text\"].apply(lambda x: cosine_similarity(search_tfidf_2, trained_vectorizer.transform([x])).tolist()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at those software firms that are most similar to our search vector. We can do that by restricting our dataframe to software firms and sorting it (```sort_values()```) by our new \"similarity\" columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "      <th>similarity_gis</th>\n",
       "      <th>similarity_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>http://srp-gmbh.de</td>\n",
       "      <td>von der über die bis zur ob als einzelarbeitsplatz oder als dezentraler facharbeitsplatz am desktop tablet oder am handy unser system bietet komponenten für alle geräte die ogctechnology bietet für eine vielzahl von anwendungsfällen werkzeuge und funktionen für die erfassung pflege bereitstellung und präsentation von geo und sachdaten im intra und internet sowie mobil unterwegs die ogctechnology wurde auf der basis von open source technologien wie java gwt openlayers und geotools entwickelt und orientiert sich konsequent an standards wie saga wc ogc isotc bei der open gis component technology handelt es sich um eine komplettlösung für den aufbau von geodateninfrastrukturen von der herstellung komplexer fachdaten über die bereitstellung bis hin zur präsentation stellt die ogctechnology alle erforderlichen werkzeuge zur verfügung einmal installiert können eine vielzahl von anwendungsfällen mit den vorhanden werkzeugen ohne weitere programmierkenntnisse umgesetzt werden konfigurieren ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                 url  \\\n",
       "179  179  http://srp-gmbh.de   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "179  von der über die bis zur ob als einzelarbeitsplatz oder als dezentraler facharbeitsplatz am desktop tablet oder am handy unser system bietet komponenten für alle geräte die ogctechnology bietet für eine vielzahl von anwendungsfällen werkzeuge und funktionen für die erfassung pflege bereitstellung und präsentation von geo und sachdaten im intra und internet sowie mobil unterwegs die ogctechnology wurde auf der basis von open source technologien wie java gwt openlayers und geotools entwickelt und orientiert sich konsequent an standards wie saga wc ogc isotc bei der open gis component technology handelt es sich um eine komplettlösung für den aufbau von geodateninfrastrukturen von der herstellung komplexer fachdaten über die bereitstellung bis hin zur präsentation stellt die ogctechnology alle erforderlichen werkzeuge zur verfügung einmal installiert können eine vielzahl von anwendungsfällen mit den vorhanden werkzeugen ohne weitere programmierkenntnisse umgesetzt werden konfigurieren ...   \n",
       "\n",
       "     predicted_software  similarity_gis  similarity_ai  \n",
       "179                   1        0.050973            0.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_hit = unlabelled_data[unlabelled_data[\"predicted_software\"] == 1].sort_values(by=[\"similarity_gis\"], ascending=False).head(1)\n",
    "top_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "      <th>similarity_gis</th>\n",
       "      <th>similarity_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>https://www.cpu-24-7.com/</td>\n",
       "      <td>individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual and standardized hpc cluster solutions for your computer aided engineering cae projects we support your digitization using cloud solutions for iot machine learning ai and big data cpu  is the leading provider of cae as a service solutions and develops and operates unique on demand services for high performance computing hpc that are based on the latest globally accepted industry standards for hardware software and applications augustbebelstraße  de  potsdam       msc software conference  german lsdyna forum  cpu  gmbh cae enterprise cae express  engineering cloud service providercae services digital engineering servicescaesolutions navigate company upcoming events contact supporttoggle navigation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>http://www.cst-gmbh.eu/company_de.html</td>\n",
       "      <td>die ist ein unternehmen im bereich der mit optischen mitteln das team der beschäftigt sich seit  mit allem was zur  zur effizienten diagnose und der analyse der gewonnenen daten gehört die firma hat ihren sitz in waldshuttiengen deutschland  gerne beschäftigen wir uns mit ungewöhnlichen und anspruchsvollen aufgaben unsere software lösungen erarbeiten wir  gemäß ihren anforderungen  sowohl für linuxembedded als auch für windows partner referenzen impressum datenschutz leistungen unternehmen beratung entwicklung produkte team anfahrt karriere en de  leistungen beratung entwicklung produkte unternehmen team anfahrt karriere referenzen partner datenschutz impressum en  de kontaktieren sie uns jetztbeleuchtungen sensoren prozesse algorithmen machinevision neuronale netzwerke tensor flow industrie  präventiver service monitoring elasticsearchdas unternehmenoptische inspektionen industrielle bildverarbeitung künstliche intelligenz internet der dingeunternehmen cst gmbh berührungslosen dia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>https://www.mach.de/</td>\n",
       "      <td>am  november  begrüßen wir daniel günther ministerpräsident des landes schleswigholstein als eröffnungsredner auf unserem führungskräfteforum innovatives management erstmals nehmen neben verwaltungsmitarbeitern in leitenden funktionen auch führungskräfte aus wirtschaft und wissenschaft sowie vertreter der startupszene teil und ermöglichen durch ihre impulse neue spannende blicke weit über den verwaltungsalltag hinaus die neuregelung des  b im umsatzsteuergesetz wirft viele fragen auf die nicht nur kirchenverwaltungen betreffen martin scholz mach fachexperte für finanzen schafft klarheit wir müssen bis zum  auf die elektronische aktenführung umstellen lässt sich das nicht mit einem dieser neuen zentralen eaktendienste realisieren wird dieser dienst rechtzeitig in betrieb gehen und alle anforderungen abdecken mit welchem aufwand müssen wir bei der einführung rechnen hier finden sie die antworten blockchain künstliche intelligenz augmented reality  was steht dahinter welche mehrwerte ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>546</td>\n",
       "      <td>https://www.insiders-technologies.de/home.html</td>\n",
       "      <td>wie ovation die stimmung ihrer kunden erkennt wie ovation mit chatbots ihren kundenservice optimiert smart flow ist unser standardprodukt für innovatives omnikanal response management kommunizieren sie mühelos und in echtzeit mit ihren kunden smart capture ist unsere app für das ortsunabhängige erfassen und einreichen von dokumenten mit mobilen endgeräten exzellenter service durch kundenkommunikation über alle kanäle  wir begleiten sie bei der digitalen transformation optimale geschäftsprozesse und exzellente kundenkommunikation  wir sind der erfahrene und starke partner an ihrer seite optimieren sie ihre prozesse für die zukunft  mit unserer expertise als langjähriger partner führender finanzdienstleister wir begleiten gesetzliche und öffentliche kassen in die digitale transformation  vertrauen auch sie unserer expertise moderne kundenkommunikation über alle kanäle  vertrauen sie unserer ausgewiesenen kompetenz und erfahrung geschäftsprozesse im saperpsystem für die digitale trans...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>https://www.aristech.de/de/</td>\n",
       "      <td>ausgestattet mit unserer hochentwickelten asr und ttstechnologie steuern sie von innovativer crmsoftware über smart homes und factories das internet of things bis hin zu telefoniedialogsystemen in sicherheitsrelevanten anwendungen unsere ausgereiften semantischen tools finden nicht wörter oder begriffe sondern bedeutungen hiermit analysieren wir ihre audio online und textdateien mit wirklich sinnvollen ergebnissen die weit über keyword spotting new topic detection oder googeln hinausgehen und machen aus ihren big data smart data manche nennen es künstliche intelligenz unsere domainvoices werden genau auf ihr individuelles vokabular trainiert damit kommen wir ihren ansprüchen einer menschlichen aussprache näher als je zuvor kundenexklusive corporate voices transportieren nicht weniger als ihr modernes image ihre corporate identity in hörbarer form quasi kurfürstenanlage   w d heidelberg phone     fax     email webtext to speech eine nuance besser unsere künstlichen stimmen weisen ei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             url  \\\n",
       "249  249                       https://www.cpu-24-7.com/   \n",
       "277  277          http://www.cst-gmbh.eu/company_de.html   \n",
       "376  376                            https://www.mach.de/   \n",
       "546  546  https://www.insiders-technologies.de/home.html   \n",
       "410  410                     https://www.aristech.de/de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "249                                                                                                       individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual and standardized hpc cluster solutions for your computer aided engineering cae projects we support your digitization using cloud solutions for iot machine learning ai and big data cpu  is the leading provider of cae as a service solutions and develops and operates unique on demand services for high performance computing hpc that are based on the latest globally accepted industry standards for hardware software and applications augustbebelstraße  de  potsdam       msc software conference  german lsdyna forum  cpu  gmbh cae enterprise cae express  engineering cloud service providercae services digital engineering servicescaesolutions navigate company upcoming events contact supporttoggle navigation   \n",
       "277  die ist ein unternehmen im bereich der mit optischen mitteln das team der beschäftigt sich seit  mit allem was zur  zur effizienten diagnose und der analyse der gewonnenen daten gehört die firma hat ihren sitz in waldshuttiengen deutschland  gerne beschäftigen wir uns mit ungewöhnlichen und anspruchsvollen aufgaben unsere software lösungen erarbeiten wir  gemäß ihren anforderungen  sowohl für linuxembedded als auch für windows partner referenzen impressum datenschutz leistungen unternehmen beratung entwicklung produkte team anfahrt karriere en de  leistungen beratung entwicklung produkte unternehmen team anfahrt karriere referenzen partner datenschutz impressum en  de kontaktieren sie uns jetztbeleuchtungen sensoren prozesse algorithmen machinevision neuronale netzwerke tensor flow industrie  präventiver service monitoring elasticsearchdas unternehmenoptische inspektionen industrielle bildverarbeitung künstliche intelligenz internet der dingeunternehmen cst gmbh berührungslosen dia...   \n",
       "376  am  november  begrüßen wir daniel günther ministerpräsident des landes schleswigholstein als eröffnungsredner auf unserem führungskräfteforum innovatives management erstmals nehmen neben verwaltungsmitarbeitern in leitenden funktionen auch führungskräfte aus wirtschaft und wissenschaft sowie vertreter der startupszene teil und ermöglichen durch ihre impulse neue spannende blicke weit über den verwaltungsalltag hinaus die neuregelung des  b im umsatzsteuergesetz wirft viele fragen auf die nicht nur kirchenverwaltungen betreffen martin scholz mach fachexperte für finanzen schafft klarheit wir müssen bis zum  auf die elektronische aktenführung umstellen lässt sich das nicht mit einem dieser neuen zentralen eaktendienste realisieren wird dieser dienst rechtzeitig in betrieb gehen und alle anforderungen abdecken mit welchem aufwand müssen wir bei der einführung rechnen hier finden sie die antworten blockchain künstliche intelligenz augmented reality  was steht dahinter welche mehrwerte ...   \n",
       "546  wie ovation die stimmung ihrer kunden erkennt wie ovation mit chatbots ihren kundenservice optimiert smart flow ist unser standardprodukt für innovatives omnikanal response management kommunizieren sie mühelos und in echtzeit mit ihren kunden smart capture ist unsere app für das ortsunabhängige erfassen und einreichen von dokumenten mit mobilen endgeräten exzellenter service durch kundenkommunikation über alle kanäle  wir begleiten sie bei der digitalen transformation optimale geschäftsprozesse und exzellente kundenkommunikation  wir sind der erfahrene und starke partner an ihrer seite optimieren sie ihre prozesse für die zukunft  mit unserer expertise als langjähriger partner führender finanzdienstleister wir begleiten gesetzliche und öffentliche kassen in die digitale transformation  vertrauen auch sie unserer expertise moderne kundenkommunikation über alle kanäle  vertrauen sie unserer ausgewiesenen kompetenz und erfahrung geschäftsprozesse im saperpsystem für die digitale trans...   \n",
       "410  ausgestattet mit unserer hochentwickelten asr und ttstechnologie steuern sie von innovativer crmsoftware über smart homes und factories das internet of things bis hin zu telefoniedialogsystemen in sicherheitsrelevanten anwendungen unsere ausgereiften semantischen tools finden nicht wörter oder begriffe sondern bedeutungen hiermit analysieren wir ihre audio online und textdateien mit wirklich sinnvollen ergebnissen die weit über keyword spotting new topic detection oder googeln hinausgehen und machen aus ihren big data smart data manche nennen es künstliche intelligenz unsere domainvoices werden genau auf ihr individuelles vokabular trainiert damit kommen wir ihren ansprüchen einer menschlichen aussprache näher als je zuvor kundenexklusive corporate voices transportieren nicht weniger als ihr modernes image ihre corporate identity in hörbarer form quasi kurfürstenanlage   w d heidelberg phone     fax     email webtext to speech eine nuance besser unsere künstlichen stimmen weisen ei...   \n",
       "\n",
       "     predicted_software  similarity_gis  similarity_ai  \n",
       "249                   1             0.0       0.081769  \n",
       "277                   1             0.0       0.055849  \n",
       "376                   1             0.0       0.045024  \n",
       "546                   1             0.0       0.034868  \n",
       "410                   1             0.0       0.033321  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_hit = unlabelled_data[unlabelled_data[\"predicted_software\"] == 1].sort_values(by=[\"similarity_ai\"], ascending=False).head(5)\n",
    "top_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(top_hit[\"url\"].values[0], width=1200, height=350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
