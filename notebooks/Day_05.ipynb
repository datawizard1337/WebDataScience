{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we will go through a typical text miningpipeline. Our goal is to train a machine learning model that classifies texts scraped from company website into two classes: \n",
    "- ```0```: Text from a non-software company website.\n",
    "- ```1```: Text from a software company website.\n",
    "\n",
    "To do so, we will do the following:\n",
    "1. Load a labelled and an unlabelled dataset.\n",
    "2. Preprocess the texts.\n",
    "3. Vectorize the texts.\n",
    "4. Split the labelled dataset into a training set and a test set.\n",
    "5. Train a logit regression classifier.\n",
    "6. Use the trained logit regression classifier to predict the missing labels in the unlabelled dataset.\n",
    "7. Calculate text similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with two different datasets: a labelled dataset and an unlabelled one. For the observations in the labelled dataset, we know whether the texts are from a software company website (\"class_1\" in the figure) or not (\"class_2\"). For the observations in the unlabelled dataset, we do not have this information and we want to **predict the missing classes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../misc/labelled_data.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load \"labelled_data.txt\", a text file with \"labelled\" website data. \"Labelled\" means that each observation is already categorized into a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in a table format with 4 columns:\n",
    "- **\"ID\"**: unique identifiers for each observation\n",
    "- **\"url\"**: the website address from where text was downloaded\n",
    "- **\"text\"**: the downloaded website text\n",
    "- **\"software\"**: the label which tells us whether a website is from a software company (\"1\") or not (\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://autzen-reimers.de</td>\n",
       "      <td>Seite: ¬´ 1 / 0 ¬ª ¬´ 1 / 0 ¬ªAUTZEN &amp; REIMERSARCH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://ibos-goerlitz.de/</td>\n",
       "      <td>Das Ingenieurb√ºro IBOS GmbH wurde am 17.09.199...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://kaizhong-vogt.de/</td>\n",
       "      <td>capanne.gittinger.de</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://baecker-holland.de/</td>\n",
       "      <td>Klicken Sie hier um zu unserem Kon¬≠takt¬≠for¬≠mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.vbhnr.de/privatkunden.html</td>\n",
       "      <td>Um Ihnen eine bessere Nutzung unserer Seite zu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     url  \\\n",
       "0   0                http://autzen-reimers.de   \n",
       "1   1               https://ibos-goerlitz.de/   \n",
       "2   2               https://kaizhong-vogt.de/   \n",
       "3   3             https://baecker-holland.de/   \n",
       "4   4  https://www.vbhnr.de/privatkunden.html   \n",
       "\n",
       "                                                text  software  \n",
       "0  Seite: ¬´ 1 / 0 ¬ª ¬´ 1 / 0 ¬ªAUTZEN & REIMERSARCH...         0  \n",
       "1  Das Ingenieurb√ºro IBOS GmbH wurde am 17.09.199...         0  \n",
       "2                               capanne.gittinger.de         0  \n",
       "3  Klicken Sie hier um zu unserem Kon¬≠takt¬≠for¬≠mu...         0  \n",
       "4  Um Ihnen eine bessere Nutzung unserer Seite zu...         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data = pd.read_csv(\"../data/labelled_data.txt\", sep=\"\\t\", encoding=\"utf-8\", error_bad_lines=False)\n",
    "labelled_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2000 rows (observations) and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the website of a random software company in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"http://autinity.de\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x283a9e74748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "random_software_url = labelled_data[labelled_data[\"software\"] == 1].sample(1)[\"url\"].values[0]\n",
    "\n",
    "display(IFrame(random_software_url, width=800, height=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a look at the \"software\" column and check out how many ```1``` (software companies) and ```0``` (other company types) we have in our data. \n",
    "\n",
    "For that we select the \"software\" column and then use pandas ```value_counts()``` method to count the ones and zeros in that column. As we can see, 1716 ```0``` and 284 ```1``` are in the dataset, which means that we have many more non-software firms than software firms in our labelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1716\n",
       "1     284\n",
       "Name: software, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[\"software\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at our text data.\n",
    "\n",
    "First, we may want to see how large our texts are. We can do so by selecting the \"text\" column and use ```apply(len)``` on it. This will return us the lenght (number of characters) of each text in our dataset. By adding pandas ```describe()``` method, we will get some descriptive statistics telling us that the mean number number of characters (2558.8) per website text, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2000.000000\n",
       "mean       2558.813500\n",
       "std        5144.796468\n",
       "min           1.000000\n",
       "25%         703.000000\n",
       "50%        1472.500000\n",
       "75%        2788.500000\n",
       "max      135504.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[\"text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelled_data[\"text\"].apply(len).plot(kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load unlabelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the same procedure as above to load a dataset with \"unlabelled\" data. In our case this means that the dataset contains website data without the \"software\" label, so we don't know whether the companies are software firms or not...but we will know soon using machine learning magic üßô!\n",
    "\n",
    "The ```shape``` method tells us that we have 937 observations and three columns (compared to the labelled dataset, we are missing the \"software\" column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://wimatec-mattes.de</td>\n",
       "      <td>Dieses Motto begleitet uns t√§glich bei der Arb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.jacobi.net/</td>\n",
       "      <td>Reactivated carbons for water and vapour treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.basf.com/de.html</td>\n",
       "      <td>Cookies helfen uns bei der Bereitstellung unse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://gjb.de</td>\n",
       "      <td>Diese Seite verwendet Frames. Frames werden vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.roda-swiss.de/</td>\n",
       "      <td>| Transparenz und Ihre Privatsph√§re sind uns w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           url  \\\n",
       "0   0      http://wimatec-mattes.de   \n",
       "1   1       https://www.jacobi.net/   \n",
       "2   2  https://www.basf.com/de.html   \n",
       "3   3                 http://gjb.de   \n",
       "4   4    https://www.roda-swiss.de/   \n",
       "\n",
       "                                                text  \n",
       "0  Dieses Motto begleitet uns t√§glich bei der Arb...  \n",
       "1  Reactivated carbons for water and vapour treat...  \n",
       "2  Cookies helfen uns bei der Bereitstellung unse...  \n",
       "3  Diese Seite verwendet Frames. Frames werden vo...  \n",
       "4  | Transparenz und Ihre Privatsph√§re sind uns w...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data = pd.read_csv(\"../data/unlabelled_data.txt\", sep=\"\\t\", encoding=\"utf-8\", error_bad_lines=False)\n",
    "print(unlabelled_data.shape)\n",
    "unlabelled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      937.000000\n",
       "mean      2524.799360\n",
       "std       4250.109905\n",
       "min          1.000000\n",
       "25%        711.000000\n",
       "50%       1491.000000\n",
       "75%       2732.000000\n",
       "max      48516.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data[\"text\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so much difference in terms of the mean between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.014140341515485"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[\"text\"].apply(len).mean() - unlabelled_data[\"text\"].apply(len).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding short texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, there are quite some websites with texts that are shorter than 500 characters and some even had only a single character. Let's exclude them because short or no text usually mean little or no information at all.\n",
    "\n",
    "After that we have 1,649 observations left in our labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before:  (2000, 4)\n",
      "Dataframe shape after:  (1649, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe shape before: \", labelled_data.shape)\n",
    "labelled_data = labelled_data[labelled_data[\"text\"].apply(len) > 499]\n",
    "print(\"Dataframe shape after: \", labelled_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure should also be applied to the unlabelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before:  (937, 3)\n",
      "Dataframe shape after:  (772, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe shape before: \", unlabelled_data.shape)\n",
    "unlabelled_data = unlabelled_data[unlabelled_data[\"text\"].apply(len) > 499]\n",
    "print(\"Dataframe shape after: \", unlabelled_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the texts in our dataset are exactly as they were downloaded from the company websites.\n",
    "\n",
    "Let's have a look at an example by displaying observation with ```ID == 1928```. We also alter a pandas option to display us more of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>http://www.brandt-transporte.com/</td>\n",
       "      <td>| My Cart Copyright ¬© 2018 . Powered byNew Products For October Monthly Specials For OctoberCategories Shop by Category Customer Services Quick Links Social MediaAMI Alexandre Mattiussi Amiri ANYA HINDMARCH Belstaff Diemme Issey Miyake Scott Tods Topo athletic Zone3 $124.52 $62.26 Save: 50% off $145.92 $72.96 Save: 50% off $125.17 $62.59 Save: 50% off $149.18 $74.59 Save: 50% off $145.29 $72.64 Save: 50% off $145.29 $72.64 Save: 50% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $592.66 $151.41 Save: 74% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                url  \\\n",
       "1928  1928  http://www.brandt-transporte.com/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "1928  | My Cart Copyright ¬© 2018 . Powered byNew Products For October Monthly Specials For OctoberCategories Shop by Category Customer Services Quick Links Social MediaAMI Alexandre Mattiussi Amiri ANYA HINDMARCH Belstaff Diemme Issey Miyake Scott Tods Topo athletic Zone3 $124.52 $62.26 Save: 50% off $145.92 $72.96 Save: 50% off $125.17 $62.59 Save: 50% off $149.18 $74.59 Save: 50% off $145.29 $72.64 Save: 50% off $145.29 $72.64 Save: 50% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $592.66 $151.41 Save: 74% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off $526.69 $140.60 Save: 73% off   \n",
       "\n",
       "      software  \n",
       "1928         0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "labelled_data[labelled_data[\"ID\"] == 1928]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there can be quiet a lot of special characters (e.g. \"%\" or \"‚Ç¨\") and numbers in the text which we may want to exclude from our further analysis. We also may want to standardise all characters to lowercase, such that \"Software\" and \"software\" are recognized as the same words by the computer.\n",
    "\n",
    "**Note** however that this is just one of many ways to preprocess your texts. Most modern Natural Language Processing (NLP) pipelines do not preprocess at all.\n",
    "\n",
    "We will import a Python's *regular expression* package and apply the ```sub(\"FILTER\", \"REPLACE_STRING\")``` function to the text column of our labelled dataset. We submit the ```sub()``` function with a so-called regular expression telling Python to delete all characters in the text that are not part of this list of characters:\n",
    "\n",
    "```\"abcdefghijklmnopqrstuvwxyz√§√∂√º√ü&. \"```\n",
    "\n",
    "The method ```lower()``` will cast all characters to lowercase, while ```strip()``` will delete \"trailing\" whitespaces (e.g. ```\"end of sentence    \"``` will become ```\"end of sentence\"```).\n",
    "\n",
    "We will replace the original text in the \"text\" column with the result of this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "labelled_data[\"text\"] = labelled_data[\"text\"].apply(lambda x: re.sub(\"[^abcdefghijklmnopqrstuvwxyz√§√∂√º√ü& ']\", \"\", str(x).lower()).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this step changed the text of our example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>http://www.brandt-transporte.com/</td>\n",
       "      <td>my cart copyright    powered bynew products for october monthly specials for octobercategories shop by category customer services quick links social mediaami alexandre mattiussi amiri anya hindmarch belstaff diemme issey miyake scott tods topo athletic zone   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                url  \\\n",
       "1928  1928  http://www.brandt-transporte.com/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   text  \\\n",
       "1928  my cart copyright    powered bynew products for october monthly specials for octobercategories shop by category customer services quick links social mediaami alexandre mattiussi amiri anya hindmarch belstaff diemme issey miyake scott tods topo athletic zone   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   save  off   \n",
       "\n",
       "      software  \n",
       "1928         0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data[labelled_data[\"ID\"] == 1928]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Let's apply the same operation on the text column of the unlabelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data[\"text\"] = unlabelled_data[\"text\"].apply(lambda x: re.sub(\"[^abcdefghijklmnopqrstuvwxyz√§√∂√º√ü& ']\", \"\", str(x).lower()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://wimatec-mattes.de</td>\n",
       "      <td>dieses motto begleitet uns t√§glich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschlei√üfesten messern f√ºr erntemaschinen und mehr als erstausr√ºster haben wir uns seit unserer gr√ºndung  als partner der landmaschinenindustrie einen namen gemacht und wir k√∂nnen mehr unser portfolio umfasst das fertigen von schwei√üteilen kunden sch√§tzen an uns qualit√§t zuverl√§ssigkeit service sowie schnelle verf√ºgbarkeit diese garantieren wir mit unserem stets gut gef√ºllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erh√§lt f√∂rdermittel der eu und des landes badenw√ºrttemberg nur  unternehmen aus ganz badenw√ºrttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde f√ºr das f√∂rderprogramm spitze auf dem land technologief√ºhrer f√ºr badenw√ºrttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung f√ºr die erfolgreiche gesch√§ftst√§tigkeit auf grundlage unserer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.jacobi.net/</td>\n",
       "      <td>reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.basf.com/de.html</td>\n",
       "      <td>cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erkl√§ren sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie √∂l und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterst√ºtzt die basf kunden und partner in mehr als  l√§ndern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem √ºberblick der basfgruppe erfahren sie mehr √ºber den basfpalmdia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.roda-swiss.de/</td>\n",
       "      <td>transparenz und ihre privatsph√§re sind uns wichtig warum cookies einfach weil sie helfen die website nutzbar zu machen ihre browsererfahrung zu verbessern und um mit social media zu interagieren klicken sie auf akzeptieren und fortfahren um die cookies zu akzeptieren und mit der seitennutzung fortzufahren datenschutzerkl√§rung wir freuen uns sehr √ºber ihr interesse an unserem unternehmen datenschutz hat einen besonders hohen stellenwert f√ºr die gesch√§ftsleitung der rodaswiss kunststofftechnik gmbh  eine nutzung der internetseiten der rodaswiss kunststofftechnik gmbh ist grunds√§tzlich ohne jede angabe personenbezogener daten m√∂glich sofern eine betroffene person besondere services unseres unternehmens √ºber unsere internetseite in anspruch nehmen m√∂chte k√∂nnte jedoch eine verarbeitung personenbezogener daten erforderlich werden ist die verarbeitung personenbezogener daten erforderlich und besteht f√ºr eine solche verarbeitung keine gesetzliche grundlage holen wir generell eine einwilli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           url  \\\n",
       "0   0      http://wimatec-mattes.de   \n",
       "1   1       https://www.jacobi.net/   \n",
       "2   2  https://www.basf.com/de.html   \n",
       "4   4    https://www.roda-swiss.de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  dieses motto begleitet uns t√§glich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschlei√üfesten messern f√ºr erntemaschinen und mehr als erstausr√ºster haben wir uns seit unserer gr√ºndung  als partner der landmaschinenindustrie einen namen gemacht und wir k√∂nnen mehr unser portfolio umfasst das fertigen von schwei√üteilen kunden sch√§tzen an uns qualit√§t zuverl√§ssigkeit service sowie schnelle verf√ºgbarkeit diese garantieren wir mit unserem stets gut gef√ºllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erh√§lt f√∂rdermittel der eu und des landes badenw√ºrttemberg nur  unternehmen aus ganz badenw√ºrttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde f√ºr das f√∂rderprogramm spitze auf dem land technologief√ºhrer f√ºr badenw√ºrttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung f√ºr die erfolgreiche gesch√§ftst√§tigkeit auf grundlage unserer ...  \n",
       "1  reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...  \n",
       "2  cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erkl√§ren sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie √∂l und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterst√ºtzt die basf kunden und partner in mehr als  l√§ndern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem √ºberblick der basfgruppe erfahren sie mehr √ºber den basfpalmdia...  \n",
       "4  transparenz und ihre privatsph√§re sind uns wichtig warum cookies einfach weil sie helfen die website nutzbar zu machen ihre browsererfahrung zu verbessern und um mit social media zu interagieren klicken sie auf akzeptieren und fortfahren um die cookies zu akzeptieren und mit der seitennutzung fortzufahren datenschutzerkl√§rung wir freuen uns sehr √ºber ihr interesse an unserem unternehmen datenschutz hat einen besonders hohen stellenwert f√ºr die gesch√§ftsleitung der rodaswiss kunststofftechnik gmbh  eine nutzung der internetseiten der rodaswiss kunststofftechnik gmbh ist grunds√§tzlich ohne jede angabe personenbezogener daten m√∂glich sofern eine betroffene person besondere services unseres unternehmens √ºber unsere internetseite in anspruch nehmen m√∂chte k√∂nnte jedoch eine verarbeitung personenbezogener daten erforderlich werden ist die verarbeitung personenbezogener daten erforderlich und besteht f√ºr eine solche verarbeitung keine gesetzliche grundlage holen wir generell eine einwilli...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning algorithms we will use require us to give numerical data to them. Raw text data as an input will not work! This means that we have to transfer our texts to some kind of numerical representation without loosing too much information. Transferring a text from a sequence of characters to a vector of numbers is called *text vectorization*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../misc/text_vectorization.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to vectorize texts, from fancy techniques like [word embeddings](!https://en.wikipedia.org/wiki/Word_embedding) and topic models like [latent dirichlet allocation (LDA)](!https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) to simple [word count models](!https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will keep it rather simple and use an approach called **TFIDF** ([term frequency‚Äìinverse document frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)) which basically counts how many times a word appears in a document and then reweights this count by the word's frequency over all known documents. The latter results in a decreased weight for common terms like \"the\", \"and\", \"house\" etc.\n",
    "- **term frequency (TF)**: The number of times a term $t$ (word) appears in a document $d$ adjusted by the length of the document (number of all words $t'$ in document $d$).\n",
    "\n",
    "\\begin{equation*}\n",
    "TF(t, d) =   \\frac{f_t,_d}{\\sum{f_{t^\\prime},_d}}\n",
    "\\end{equation*}\n",
    "\n",
    "- **inverse document frequency (IDF)**: Counts the number of documents $n_t$ an individual term $t$ appears over all documents $N$.\n",
    "\\begin{equation*}\n",
    "IDF(t) =   log{\\frac{N}{1 + n_t}}\n",
    "\\end{equation*}\n",
    "\n",
    "- **term frequency-inverse document frequency (TFIDF)**: This step weights down common words like \"the\" and gives more weight to rare words like \"software\".\n",
    "\n",
    "\\begin{equation*}\n",
    "TFIDF(t, d) = TF(t, d) * IDF(t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use scikit-learn's [TFIDF Vectorizer](!https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to generate TFIDF vectors from our texts. Scikit-learn is the most popular machine learning package for Python and includes all kinds of ML algorithms from clustering to classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"500\"\n",
       "            src=\"https://scikit-learn.org/stable/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x283aa281408>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(IFrame(\"https://scikit-learn.org/stable/\", width=1200, height=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn (sklearn) should comes pre-installed with Anaconda. Otherwise you would install it using pip:\n",
    "\n",
    "```pip install -U scikit-learn```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating TFIDF vectors from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import sklearn's ```TfidfVectorizer``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to initialize a TFIDF vectorizer. We pass the ```analyzer=\"word\"``` parameter to tell the function to analyze our texts at the level of words (rather than single characters, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to teach our vocabulary to the vectorizer. For that we can use the vectorizer's ```fit()``` method on our texts. In this step, the vectorizer also calculates the inverse document frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_vectorizer = vectorizer.fit(labelled_data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the fitted vectorizer's ```transform()``` method to transform any text document to a TFIDF vector.\n",
    "\n",
    "Let's transform the sentence ```\"dies ist ein Test\"``` and output the resulting vector using Python's ```print()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 64619)\t0.7674788380733668\n",
      "  (0, 34005)\t0.22768716559203767\n",
      "  (0, 16620)\t0.2383998438323033\n",
      "  (0, 14515)\t0.5498184265691286\n"
     ]
    }
   ],
   "source": [
    "example_tfidf = fitted_vectorizer.transform([\"dies ist ein test\"])\n",
    "print(example_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output you see is a so-called *sparse matrix*. In a sparse matrix, only non-zero elements are memorized and mapped using indexes. This actually saves A LOT of memory. In the example above, there are only four non-zero elements in the matrix and their coordinates/indexes are given in the left parantheses. The elements on the right hand side give you the corresponding TFIDF value for the word mapped by the coordinates.\n",
    "\n",
    "Let's have a look at the vocabulary that the vectorizer learned from our data. We call the ```vocabulary_``` method on the fitted vectorizer to retrieve then full vocabulary and the use a ```for``` loop to print the first items in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('das', 13209)\n",
      "('ingenieurb√ºro', 32913)\n",
      "('ibos', 31714)\n",
      "('gmbh', 27194)\n",
      "('wurde', 74328)\n",
      "('am', 1890)\n",
      "('in', 32182)\n",
      "('g√∂rlitz', 28454)\n",
      "('gegr√ºndet', 24982)\n",
      "('unser', 67469)\n",
      "('handlungsschwerpunkt', 28901)\n"
     ]
    }
   ],
   "source": [
    "vocabulary = fitted_vectorizer.vocabulary_\n",
    "\n",
    "#little loop to print the first items in the vocabulary\n",
    "for count, item in enumerate(iter(vocabulary.items())):\n",
    "    print(item)\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the vocabulary index of a word directly (this only works for words that were learned during the ```fit()``` and thus are in the vocabulary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64619"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'istari'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0663ec5a4630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"istari\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'istari'"
     ]
    }
   ],
   "source": [
    "vocabulary[\"istari\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how many words are in our vocabulary, actually? We can see that by calculating its length using Python's ```len()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76713"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are quiet a lot of words. It may be a good idea to shrink down our vocabulary a bit, especially because this will reduce both memory consumption and the required computational power when we start doing ML magic!\n",
    "\n",
    "A common approach to do so is to apply so-called *popularity-based filtering*. Hereby, we exclude very common and/or extremly uncommon words from our vocabulary. This can be achieved by passing the corresponding parameters to the vectorizer during fitting. \n",
    "\n",
    "Let's overwrite our vectorizer and create a new one which includes only those words that appear in a maximum (```max_df```) of 80% and a minimum (```min_df```) of 1% of the websites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', min_df=0.01, max_df=0.8)\n",
    "fitted_vectorizer = vectorizer.fit(labelled_data[\"text\"])\n",
    "vocabulary = fitted_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary should be way smaller now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2622"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have excluded super frequent words like \"der\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'der'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-f44d00c66d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"der\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'der'"
     ]
    }
   ],
   "source": [
    "vocabulary[\"der\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium common words like \"test\", should be still included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2151"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split our labelled dataset into a **training set** and a **test set**. The training set will be used to train our machine learning model to predict the correct labels (classes). After the training, we will use the trained model to predict the labels of all the observations in the test set, which was not used for training. Based on the prediction performance in the test set, we can evaluate the prediction performance of our trained model.\n",
    "\n",
    "This two-step approach is used to make sure that the ML model does not simply memorize all the observations in the training data, but instead derives universal rules on how to distinguish the different classes. This universal ability is called **generalization** and is very desireable in machine learning. In contrast, the over-memorization of the training set and a model's resulting bad performance using other data is called **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../misc/training_split.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **training** of a machine learning model describes the process of teaching the model how to achive a certain learning task. In the case of a classification tasks, we give the model a list of properties $X$ (**features** or **attributes**) that are used to calculate a predicted outcome (**label** or **class**) $\\hat{Y}$. We then compare the predicted outcome $\\hat{Y}$ to the true outcome $Y$ that we know because we have a labelled dataset. In our example, we will use the trained ML model to predict whether a text comes from a software company website ($\\hat{Y}$ = 1 or 0) and the compare our predictions against the true values of $Y$. \n",
    "\n",
    "The difference between the predicted and the true outcome is then used to calculate an **error**. We then start to **optimize** (**train**) the model by adjusting its internal numbers $W$ (**weights**) to minimize the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../misc/training.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of training is called **supervised learning** because we supervise the training outcome and assess each output predicted label of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the features (attributes) of our observations are the texts as TFIDF vectors and our labels are the \"1\" and \"0\" classes in the \"software\" column. In another ML task, the attributes could be, for example, the properties/features of a house (location, size, number of rooms etc.) and the outcome we want to predict could be the house's selling price.\n",
    "\n",
    "So let's first shuffle our data (always do that to make sure there is no systematic order in your data) and then create a list with our features $X$ and a list with the corresponding labels $Y$. For the features we select the text column from our labelled dataset and transform them to TFIDF vectors using our trained vactorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data = labelled_data.sample(frac=1.0, random_state=12) # a fixed random_state ensures that the shuffle will result in the same order every time\n",
    "features = fitted_vectorizer.transform(labelled_data[\"text\"])\n",
    "labels = labelled_data[\"software\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber that we hat 1,649 observations in our labelled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first 1,250 observations for the training set. The remaining obseravtions will be assigned to the test set and put aside for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trainset = features[:1250]\n",
    "labels_trainset = labels[:1250]\n",
    "\n",
    "features_testset = features[1250:]\n",
    "labels_testset = labels[1250:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: In a real life ML task, you should train your tfidf vectorizer on the training dataset only and not the test set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Training a logit regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our first model. We will start with something basic: A [logistic regression classifier](https://en.wikipedia.org/wiki/Logistic_regression). This classifier is a pretty popular model for binary outcome variables. Again, we will use scikit-learn for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to initialize the logisitic regression model. We pass it the parameter ```class_weight=\"balanced\"``` because we have a pretty unbalanced dataset (one class in way more frequent than the other). The ```\"balanced\"``` parameter will make sure that the model will pay more attention to the infrequent class (in our case the \"software\"  ```1``` class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_classifier = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the classifier using its ```fit()``` method and passing the features and corresponding labels of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_logit_classifier = logit_classifier.fit(features_trainset, labels_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just trained your first machine learning model! But how good is it at distinguishing the web texts of software firms from other firm types? \n",
    "\n",
    "Let's test that with an example sentence that we transfer to a TFIDF vector using our trained vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bauernhof_tfidf = fitted_vectorizer.transform([\"das ist ein bauernhof und wir bauen getreide an\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1208)\t0.279137030214422\n",
      "  (0, 564)\t0.2922704239296758\n",
      "  (0, 441)\t0.2944505058129105\n",
      "  (0, 206)\t0.8119552312781735\n",
      "  (0, 55)\t0.30114468231328534\n"
     ]
    }
   ],
   "source": [
    "print(bauernhof_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this TFIDF vector to our trained logit classifier and tell it to predict its label using the ```predict()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_logit_classifier.predict(bauernhof_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted label is ```0``` (aka \"not a software company\"). Awesome ü•≥ü•≥ü•≥!\n",
    "\n",
    "We can also check out the probability for both classes by using the ```predict_proba()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67518489, 0.32481511]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_logit_classifier.predict_proba(bauernhof_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number above gives you the probability that the label is \"0\" while the second number is the probability that the label is ```1```. So the classifier is not too confident (about 60-65%) that the text comes from the website of a non-software company (**WARNING: Your results may differ!**).\n",
    "\n",
    "Let's try one more example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03145259, 0.96854741]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programmer_tfidf = fitted_vectorizer.transform([\"wir programmieren software\"])\n",
    "trained_logit_classifier.predict_proba(programmer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_logit_classifier.predict(programmer_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! In this example, the model is absolutely sure (97%) that the text comes from a sofware company.\n",
    "\n",
    "We should now test our trained classifier using the test set which we put aside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = trained_logit_classifier.predict(features_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now ```print()``` the predicted labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the true labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels_testset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and compare them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True False  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True False  True False  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True False  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False False  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True False  True  True  True False  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False  True  True  True  True  True  True  True  True False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True False  True False  True\n",
      " False  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True False  True  True False  True False\n",
      "  True  True  True  True  True False False  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels == labels_testset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow...at first glace that looks pretty convincing. It seems like most of the predicted labels match their true counterparts, but not all of them.\n",
    "\n",
    "Let's quantify the classifier's prediction performance by generating a scikit-learn **classification report**. The report contains several measures that allow us to evaluate the performance of our trained model in the test set:\n",
    "\n",
    "- **precision**: the fraction of observations that were predicted to have label $\\hat{y} = 1$ and that actually have the true label $y = 1$ and vice versa.\n",
    "- **recall**: the fraction of observations that have the true label $y = 1$ and that were predicted to have $\\hat{y} = 1$ and vice versa.\n",
    "- **f1-score**: a composite measure that combines both precision and recall.\n",
    "- **support**: simply the number of observations with this true label in the test set.\n",
    "\n",
    "<img src=\"../misc/classification_report.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       323\n",
      "           1       0.71      0.79      0.75        76\n",
      "\n",
      "    accuracy                           0.90       399\n",
      "   macro avg       0.83      0.86      0.84       399\n",
      "weighted avg       0.90      0.90      0.90       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels_testset, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad! As you can see, the classification report gives you precision, recall, f1-score, and support for both labels (```1``` and ```0```). We could summarize the report as follows:\n",
    "- 95% of the observations that were labeled ```0``` by the classifier actually have the true label ```0```. For label ```1``` this value is only 71%\n",
    "- 92% of the observations that have the true label ```0``` were also predicted to have have the label ```0``` by the classifier. For label ```1``` this value is only 75%.\n",
    "\n",
    "So if our goal was to identify most of the software firms in the unlabelled dataset (**true positives**) while limiting the number of non-software firms that are wrongly classified as software firm (**false positives**), we could say:\n",
    "\n",
    "*7 out of 10 firms that were predicted to be software firms are actually software firms and we are able to recover 8 of 10 software firms in the dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we can create a new column with our predicted labels in our labelled dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data.loc[labelled_data.index[1250:], 'prediction'] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and have a look at a random observations that has been assigned the wrong class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>software</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>1365</td>\n",
       "      <td>https://www.ave-online.de/</td>\n",
       "      <td>der wichtigste wettbewerbsfaktor auf dem energiemarkt ist die zufriedenheit der energiekunden allerdings kommt kundenzufriedenheit selten von liebe auf den ersten blick deshalb handeln wir f√ºr sie an allen kontaktpunkten zwischen ihnen und ihren kunden und f√ºllen diese mit positiven kundenerlebnissen in der kundenbeziehungspflege kommt es  wie in jeder guten beziehung  selten auf einzelma√ünahmen an was n√ºtzt ein bunter blumenstrau√ü wenn es an empathie gesp√ºr und am richtigen umgangston f√ºr den umworbenen mangelt wenig deshalb entwickeln wir gemeinsam mit ihnen eine ganzheitliche kundenservicestrategie die ihre kunden lieben werden  kundenerfahrungsmanagement das gute gef√ºhl ihrer kunden liegt uns sehr am herzen deshalb haben wir den anspruch f√ºr unternehmen des energiemarkts passgenaue dienstleistungen anzubieten mit rund  mitarbeitern erbringen wir f√ºr √ºber  kunden aller sparten marktrollen und strukturen individuelle prozessdienstleistungen entlang der costumer journey  und zwar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                         url  \\\n",
       "1365  1365  https://www.ave-online.de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "1365  der wichtigste wettbewerbsfaktor auf dem energiemarkt ist die zufriedenheit der energiekunden allerdings kommt kundenzufriedenheit selten von liebe auf den ersten blick deshalb handeln wir f√ºr sie an allen kontaktpunkten zwischen ihnen und ihren kunden und f√ºllen diese mit positiven kundenerlebnissen in der kundenbeziehungspflege kommt es  wie in jeder guten beziehung  selten auf einzelma√ünahmen an was n√ºtzt ein bunter blumenstrau√ü wenn es an empathie gesp√ºr und am richtigen umgangston f√ºr den umworbenen mangelt wenig deshalb entwickeln wir gemeinsam mit ihnen eine ganzheitliche kundenservicestrategie die ihre kunden lieben werden  kundenerfahrungsmanagement das gute gef√ºhl ihrer kunden liegt uns sehr am herzen deshalb haben wir den anspruch f√ºr unternehmen des energiemarkts passgenaue dienstleistungen anzubieten mit rund  mitarbeitern erbringen wir f√ºr √ºber  kunden aller sparten marktrollen und strukturen individuelle prozessdienstleistungen entlang der costumer journey  und zwar ...   \n",
       "\n",
       "      software  prediction  \n",
       "1365         0         1.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_prediction = labelled_data[(labelled_data[\"software\"] != labelled_data[\"prediction\"]) & (labelled_data[\"prediction\"].notnull())].sample(1)\n",
    "wrong_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"350\"\n",
       "            src=\"https://www.ave-online.de/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x283acf80e08>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(IFrame(wrong_prediction[\"url\"].values[0], width=1200, height=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final step, we create a new column \"software\" in our unlabelled dataset and predict the labels using our trained logit classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://wimatec-mattes.de</td>\n",
       "      <td>dieses motto begleitet uns t√§glich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschlei√üfesten messern f√ºr erntemaschinen und mehr als erstausr√ºster haben wir uns seit unserer gr√ºndung  als partner der landmaschinenindustrie einen namen gemacht und wir k√∂nnen mehr unser portfolio umfasst das fertigen von schwei√üteilen kunden sch√§tzen an uns qualit√§t zuverl√§ssigkeit service sowie schnelle verf√ºgbarkeit diese garantieren wir mit unserem stets gut gef√ºllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erh√§lt f√∂rdermittel der eu und des landes badenw√ºrttemberg nur  unternehmen aus ganz badenw√ºrttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde f√ºr das f√∂rderprogramm spitze auf dem land technologief√ºhrer f√ºr badenw√ºrttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung f√ºr die erfolgreiche gesch√§ftst√§tigkeit auf grundlage unserer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.jacobi.net/</td>\n",
       "      <td>reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.basf.com/de.html</td>\n",
       "      <td>cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erkl√§ren sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie √∂l und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterst√ºtzt die basf kunden und partner in mehr als  l√§ndern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem √ºberblick der basfgruppe erfahren sie mehr √ºber den basfpalmdia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           url  \\\n",
       "0   0      http://wimatec-mattes.de   \n",
       "1   1       https://www.jacobi.net/   \n",
       "2   2  https://www.basf.com/de.html   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  dieses motto begleitet uns t√§glich bei der arbeit und ist uns gleichzeitig ansporn wir sind spezialisiert auf die herstellung von hochverschlei√üfesten messern f√ºr erntemaschinen und mehr als erstausr√ºster haben wir uns seit unserer gr√ºndung  als partner der landmaschinenindustrie einen namen gemacht und wir k√∂nnen mehr unser portfolio umfasst das fertigen von schwei√üteilen kunden sch√§tzen an uns qualit√§t zuverl√§ssigkeit service sowie schnelle verf√ºgbarkeit diese garantieren wir mit unserem stets gut gef√ºllten lager und bieten damit kunden vor allem in saisonalen hochzeiten sicherheit wimatec mattes gmbh erh√§lt f√∂rdermittel der eu und des landes badenw√ºrttemberg nur  unternehmen aus ganz badenw√ºrttemberg schafften das qualifikationsauswahlverfahren der siebten auswahlrunde f√ºr das f√∂rderprogramm spitze auf dem land technologief√ºhrer f√ºr badenw√ºrttemberg die wimatec mattes gmbh hat es in diese top  geschafft voraussetzung f√ºr die erfolgreiche gesch√§ftst√§tigkeit auf grundlage unserer ...   \n",
       "1  reactivated carbons for water and vapour treatment control of odours and contaminants from waste air streams as well as purification of process gases to remove unwanted impurities wastewater treatment control of vapour phase emissions and process chemical applications in petrochemical facilities treatment of flue gas emissions from waste incinerators power plants and other sources for mercury and dioxin control decolorisation and impurity removal from various process food streams chemical refining duties activated carbons used for precious metals recovery specialty activated carbons for industrial and military grade respirators as well as collective protection devices purification of pharmaceutical compounds and medicinal applications including ingestible carbons point of use pou and point of entry poe water treatment devices activated carbon is a processed natural material that is high in carbon content for example coal wood or coconut are perfect raw materials for this the result...   \n",
       "2  cookies helfen uns bei der bereitstellung unserer dienste durch die nutzung unserer dienste erkl√§ren sie sich damit einverstanden dass wir cookies setzen hello  you are logged in with access to additional information please login with your username and password you want to purchase products or view order status from basf se would you like to register to get personalized information to get additional information like specific downloads you want to purchase products or view order status from basf se please provide your registered email id to reset your password unser portfolio reicht von chemikalien kunststoffen und veredlungsprodukten bis hin zu pflanzenschutzmitteln feinchemikalien sowie √∂l und gas mit sechs verbundstandorten und  weiteren produktionsstandorten unterst√ºtzt die basf kunden und partner in mehr als  l√§ndern weltweit  oktober  besuchen sie unsere webseite mit informationen rund um die basfaktie sowie einem √ºberblick der basfgruppe erfahren sie mehr √ºber den basfpalmdia...   \n",
       "\n",
       "   predicted_software  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data[\"predicted_software\"] = unlabelled_data[\"text\"].apply(lambda text: trained_logit_classifier.predict(fitted_vectorizer.transform([text]))[0])\n",
    "unlabelled_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ML model found about 125 software firms in our unlabelled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    647\n",
       "1    125\n",
       "Name: predicted_software, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data[\"predicted_software\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>709</td>\n",
       "      <td>https://www.rathgeber-gmbh.de/</td>\n",
       "      <td>rathgeber gmbh industriestra√üe   mittenaar tel      fax      rathgeber magyarorszg kft bernyi t  h szkesfehrvrkontaktieren sie unsmittenaarhessen szkesfehrvrungarnthermostate und regler rathgeber regler f√ºr feste brennstoffe kapillarrohr thermostate sonstige anwendungen sie heizen  wir regelnkonstruktion entwicklung produktion produktionhome aktuelles  karriere produkte regler f√ºr feste brennstoffe kapillarrohrthermostate sonstige anwedungen zubeh√∂r √ºber uns auslandsvertretungen kontakt einzelheiten einzelheiten einzelheiten rathgeber  ihr leistungsf√§higer partner wenn es um thermostatische regelungen sowohl bei elektrischen anlagen als auch bei feuerungsst√§tten geht mit einem team von engagierten und qualifizierten mitarbeitern fertigen wir in eigenen produktionsst√§tten regler f√ºr feste brennstoffe kapillarrohrthermostate entladeregler sowie umfangreiches zubeh√∂r f√ºr ihre planung steht ihnen unser team und unsere technik zur verf√ºgung nutzen sie unser angebot und beschreiben sie u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                             url  \\\n",
       "709  709  https://www.rathgeber-gmbh.de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "709  rathgeber gmbh industriestra√üe   mittenaar tel      fax      rathgeber magyarorszg kft bernyi t  h szkesfehrvrkontaktieren sie unsmittenaarhessen szkesfehrvrungarnthermostate und regler rathgeber regler f√ºr feste brennstoffe kapillarrohr thermostate sonstige anwendungen sie heizen  wir regelnkonstruktion entwicklung produktion produktionhome aktuelles  karriere produkte regler f√ºr feste brennstoffe kapillarrohrthermostate sonstige anwedungen zubeh√∂r √ºber uns auslandsvertretungen kontakt einzelheiten einzelheiten einzelheiten rathgeber  ihr leistungsf√§higer partner wenn es um thermostatische regelungen sowohl bei elektrischen anlagen als auch bei feuerungsst√§tten geht mit einem team von engagierten und qualifizierten mitarbeitern fertigen wir in eigenen produktionsst√§tten regler f√ºr feste brennstoffe kapillarrohrthermostate entladeregler sowie umfangreiches zubeh√∂r f√ºr ihre planung steht ihnen unser team und unsere technik zur verf√ºgung nutzen sie unser angebot und beschreiben sie u...   \n",
       "\n",
       "     predicted_software  \n",
       "709                   0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Calculating text similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing texts as vectors has another advantage: It allows us to easily calculate distances between pairs of texts. By calculating such pairwise distances, we are able to identify pairs of texts that are very similar (close) or dissimilar (distant) to each other. Calculating the distances between observations in our dataset can be understood as comparing the business activities of the companies as they are described on their websites. \n",
    "\n",
    "Let's try this out and see whether we can find Geographic Information System (GIS) software companies in our unlabelled dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to retrain our TFIDF vectorizer on our unlabelled dataset without the popularity-based filtering. This makes sure that all the words (about 42,000) in the unlabelled dataset are included in the resulting vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42336"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word')\n",
    "trained_vectorizer = vectorizer.fit(unlabelled_data[\"text\"])\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a single TFIDF vector from a description of the company type we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tfidf = trained_vectorizer.transform([\"gis geographie geographische informationssysteme geodaten\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another TFIDF with AI keywords too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tfidf_2 = trained_vectorizer.transform([\"k√ºnstliche intelligenz artificial intelligence ai ki machine learning maschinelles lernen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17874)\t0.5365635470684603\n",
      "  (0, 14829)\t0.5532618101527164\n",
      "  (0, 14052)\t0.637182022175651\n"
     ]
    }
   ],
   "source": [
    "print(search_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the popular [**cosine similarity**](!https://www.machinelearningplus.com/nlp/cosine-similarity/) to calculate the similarity between our TFIDF vectors. Cosine similarity measures the similarity between vectors based on their orientation in the high-dimensional vector space they live in. The smaller the angle between two documents, the more similar they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will use a function from scikit-learn [```cosine_similarity()```](!https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) to calculate the cosine similarity between our search TFIDF vectors and the TFIDF vectors representing the company website texts in our unlabelled dataset. We do so by applying the function to the text column and creating a new column \"similarity\" with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "unlabelled_data[\"similarity_gis\"] = unlabelled_data[\"text\"].apply(lambda x: cosine_similarity(search_tfidf, trained_vectorizer.transform([x])).tolist()[0][0])\n",
    "\n",
    "unlabelled_data[\"similarity_ai\"] = unlabelled_data[\"text\"].apply(lambda x: cosine_similarity(search_tfidf_2, trained_vectorizer.transform([x])).tolist()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at those software firms that are most similar to our search vector. We can do that by restricting our dataframe to software firms and sorting it (```sort_values()```) by our new \"similarity\" columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "      <th>similarity_gis</th>\n",
       "      <th>similarity_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>http://srp-gmbh.de</td>\n",
       "      <td>von der √ºber die bis zur ob als einzelarbeitsplatz oder als dezentraler facharbeitsplatz am desktop tablet oder am handy unser system bietet komponenten f√ºr alle ger√§te die ogctechnology bietet f√ºr eine vielzahl von anwendungsf√§llen werkzeuge und funktionen f√ºr die erfassung pflege bereitstellung und pr√§sentation von geo und sachdaten im intra und internet sowie mobil unterwegs die ogctechnology wurde auf der basis von open source technologien wie java gwt openlayers und geotools entwickelt und orientiert sich konsequent an standards wie saga wc ogc isotc bei der open gis component technology handelt es sich um eine komplettl√∂sung f√ºr den aufbau von geodateninfrastrukturen von der herstellung komplexer fachdaten √ºber die bereitstellung bis hin zur pr√§sentation stellt die ogctechnology alle erforderlichen werkzeuge zur verf√ºgung einmal installiert k√∂nnen eine vielzahl von anwendungsf√§llen mit den vorhanden werkzeugen ohne weitere programmierkenntnisse umgesetzt werden konfigurieren ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                 url  \\\n",
       "179  179  http://srp-gmbh.de   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "179  von der √ºber die bis zur ob als einzelarbeitsplatz oder als dezentraler facharbeitsplatz am desktop tablet oder am handy unser system bietet komponenten f√ºr alle ger√§te die ogctechnology bietet f√ºr eine vielzahl von anwendungsf√§llen werkzeuge und funktionen f√ºr die erfassung pflege bereitstellung und pr√§sentation von geo und sachdaten im intra und internet sowie mobil unterwegs die ogctechnology wurde auf der basis von open source technologien wie java gwt openlayers und geotools entwickelt und orientiert sich konsequent an standards wie saga wc ogc isotc bei der open gis component technology handelt es sich um eine komplettl√∂sung f√ºr den aufbau von geodateninfrastrukturen von der herstellung komplexer fachdaten √ºber die bereitstellung bis hin zur pr√§sentation stellt die ogctechnology alle erforderlichen werkzeuge zur verf√ºgung einmal installiert k√∂nnen eine vielzahl von anwendungsf√§llen mit den vorhanden werkzeugen ohne weitere programmierkenntnisse umgesetzt werden konfigurieren ...   \n",
       "\n",
       "     predicted_software  similarity_gis  similarity_ai  \n",
       "179                   1        0.050973            0.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_hit = unlabelled_data[unlabelled_data[\"predicted_software\"] == 1].sort_values(by=[\"similarity_gis\"], ascending=False).head(1)\n",
    "top_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"350\"\n",
       "            src=\"http://srp-gmbh.de\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x283aab44108>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(IFrame(top_hit[\"url\"].values[0], width=1200, height=350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_software</th>\n",
       "      <th>similarity_gis</th>\n",
       "      <th>similarity_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>https://www.cpu-24-7.com/</td>\n",
       "      <td>individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual and standardized hpc cluster solutions for your computer aided engineering cae projects we support your digitization using cloud solutions for iot machine learning ai and big data cpu  is the leading provider of cae as a service solutions and develops and operates unique on demand services for high performance computing hpc that are based on the latest globally accepted industry standards for hardware software and applications augustbebelstra√üe  de  potsdam       msc software conference  german lsdyna forum  cpu  gmbh cae enterprise cae express  engineering cloud service providercae services digital engineering servicescaesolutions navigate company upcoming events contact supporttoggle navigation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>http://www.cst-gmbh.eu/company_de.html</td>\n",
       "      <td>die ist ein unternehmen im bereich der mit optischen mitteln das team der besch√§ftigt sich seit  mit allem was zur  zur effizienten diagnose und der analyse der gewonnenen daten geh√∂rt die firma hat ihren sitz in waldshuttiengen deutschland  gerne besch√§ftigen wir uns mit ungew√∂hnlichen und anspruchsvollen aufgaben unsere software l√∂sungen erarbeiten wir  gem√§√ü ihren anforderungen  sowohl f√ºr linuxembedded als auch f√ºr windows partner referenzen impressum datenschutz leistungen unternehmen beratung entwicklung produkte team anfahrt karriere en de  leistungen beratung entwicklung produkte unternehmen team anfahrt karriere referenzen partner datenschutz impressum en  de kontaktieren sie uns jetztbeleuchtungen sensoren prozesse algorithmen machinevision neuronale netzwerke tensor flow industrie  pr√§ventiver service monitoring elasticsearchdas unternehmenoptische inspektionen industrielle bildverarbeitung k√ºnstliche intelligenz internet der dingeunternehmen cst gmbh ber√ºhrungslosen dia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>https://www.mach.de/</td>\n",
       "      <td>am  november  begr√º√üen wir daniel g√ºnther ministerpr√§sident des landes schleswigholstein als er√∂ffnungsredner auf unserem f√ºhrungskr√§fteforum innovatives management erstmals nehmen neben verwaltungsmitarbeitern in leitenden funktionen auch f√ºhrungskr√§fte aus wirtschaft und wissenschaft sowie vertreter der startupszene teil und erm√∂glichen durch ihre impulse neue spannende blicke weit √ºber den verwaltungsalltag hinaus die neuregelung des  b im umsatzsteuergesetz wirft viele fragen auf die nicht nur kirchenverwaltungen betreffen martin scholz mach fachexperte f√ºr finanzen schafft klarheit wir m√ºssen bis zum  auf die elektronische aktenf√ºhrung umstellen l√§sst sich das nicht mit einem dieser neuen zentralen eaktendienste realisieren wird dieser dienst rechtzeitig in betrieb gehen und alle anforderungen abdecken mit welchem aufwand m√ºssen wir bei der einf√ºhrung rechnen hier finden sie die antworten blockchain k√ºnstliche intelligenz augmented reality  was steht dahinter welche mehrwerte ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>546</td>\n",
       "      <td>https://www.insiders-technologies.de/home.html</td>\n",
       "      <td>wie ovation die stimmung ihrer kunden erkennt wie ovation mit chatbots ihren kundenservice optimiert smart flow ist unser standardprodukt f√ºr innovatives omnikanal response management kommunizieren sie m√ºhelos und in echtzeit mit ihren kunden smart capture ist unsere app f√ºr das ortsunabh√§ngige erfassen und einreichen von dokumenten mit mobilen endger√§ten exzellenter service durch kundenkommunikation √ºber alle kan√§le  wir begleiten sie bei der digitalen transformation optimale gesch√§ftsprozesse und exzellente kundenkommunikation  wir sind der erfahrene und starke partner an ihrer seite optimieren sie ihre prozesse f√ºr die zukunft  mit unserer expertise als langj√§hriger partner f√ºhrender finanzdienstleister wir begleiten gesetzliche und √∂ffentliche kassen in die digitale transformation  vertrauen auch sie unserer expertise moderne kundenkommunikation √ºber alle kan√§le  vertrauen sie unserer ausgewiesenen kompetenz und erfahrung gesch√§ftsprozesse im saperpsystem f√ºr die digitale trans...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>https://www.aristech.de/de/</td>\n",
       "      <td>ausgestattet mit unserer hochentwickelten asr und ttstechnologie steuern sie von innovativer crmsoftware √ºber smart homes und factories das internet of things bis hin zu telefoniedialogsystemen in sicherheitsrelevanten anwendungen unsere ausgereiften semantischen tools finden nicht w√∂rter oder begriffe sondern bedeutungen hiermit analysieren wir ihre audio online und textdateien mit wirklich sinnvollen ergebnissen die weit √ºber keyword spotting new topic detection oder googeln hinausgehen und machen aus ihren big data smart data manche nennen es k√ºnstliche intelligenz unsere domainvoices werden genau auf ihr individuelles vokabular trainiert damit kommen wir ihren anspr√ºchen einer menschlichen aussprache n√§her als je zuvor kundenexklusive corporate voices transportieren nicht weniger als ihr modernes image ihre corporate identity in h√∂rbarer form quasi kurf√ºrstenanlage   w d heidelberg phone     fax     email webtext to speech eine nuance besser unsere k√ºnstlichen stimmen weisen ei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             url  \\\n",
       "249  249                       https://www.cpu-24-7.com/   \n",
       "277  277          http://www.cst-gmbh.eu/company_de.html   \n",
       "376  376                            https://www.mach.de/   \n",
       "546  546  https://www.insiders-technologies.de/home.html   \n",
       "410  410                     https://www.aristech.de/de/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "249                                                                                                       individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual on demand hpcclustersolutions cae as a service scalable ready to use and secure individual and standardized hpc cluster solutions for your computer aided engineering cae projects we support your digitization using cloud solutions for iot machine learning ai and big data cpu  is the leading provider of cae as a service solutions and develops and operates unique on demand services for high performance computing hpc that are based on the latest globally accepted industry standards for hardware software and applications augustbebelstra√üe  de  potsdam       msc software conference  german lsdyna forum  cpu  gmbh cae enterprise cae express  engineering cloud service providercae services digital engineering servicescaesolutions navigate company upcoming events contact supporttoggle navigation   \n",
       "277  die ist ein unternehmen im bereich der mit optischen mitteln das team der besch√§ftigt sich seit  mit allem was zur  zur effizienten diagnose und der analyse der gewonnenen daten geh√∂rt die firma hat ihren sitz in waldshuttiengen deutschland  gerne besch√§ftigen wir uns mit ungew√∂hnlichen und anspruchsvollen aufgaben unsere software l√∂sungen erarbeiten wir  gem√§√ü ihren anforderungen  sowohl f√ºr linuxembedded als auch f√ºr windows partner referenzen impressum datenschutz leistungen unternehmen beratung entwicklung produkte team anfahrt karriere en de  leistungen beratung entwicklung produkte unternehmen team anfahrt karriere referenzen partner datenschutz impressum en  de kontaktieren sie uns jetztbeleuchtungen sensoren prozesse algorithmen machinevision neuronale netzwerke tensor flow industrie  pr√§ventiver service monitoring elasticsearchdas unternehmenoptische inspektionen industrielle bildverarbeitung k√ºnstliche intelligenz internet der dingeunternehmen cst gmbh ber√ºhrungslosen dia...   \n",
       "376  am  november  begr√º√üen wir daniel g√ºnther ministerpr√§sident des landes schleswigholstein als er√∂ffnungsredner auf unserem f√ºhrungskr√§fteforum innovatives management erstmals nehmen neben verwaltungsmitarbeitern in leitenden funktionen auch f√ºhrungskr√§fte aus wirtschaft und wissenschaft sowie vertreter der startupszene teil und erm√∂glichen durch ihre impulse neue spannende blicke weit √ºber den verwaltungsalltag hinaus die neuregelung des  b im umsatzsteuergesetz wirft viele fragen auf die nicht nur kirchenverwaltungen betreffen martin scholz mach fachexperte f√ºr finanzen schafft klarheit wir m√ºssen bis zum  auf die elektronische aktenf√ºhrung umstellen l√§sst sich das nicht mit einem dieser neuen zentralen eaktendienste realisieren wird dieser dienst rechtzeitig in betrieb gehen und alle anforderungen abdecken mit welchem aufwand m√ºssen wir bei der einf√ºhrung rechnen hier finden sie die antworten blockchain k√ºnstliche intelligenz augmented reality  was steht dahinter welche mehrwerte ...   \n",
       "546  wie ovation die stimmung ihrer kunden erkennt wie ovation mit chatbots ihren kundenservice optimiert smart flow ist unser standardprodukt f√ºr innovatives omnikanal response management kommunizieren sie m√ºhelos und in echtzeit mit ihren kunden smart capture ist unsere app f√ºr das ortsunabh√§ngige erfassen und einreichen von dokumenten mit mobilen endger√§ten exzellenter service durch kundenkommunikation √ºber alle kan√§le  wir begleiten sie bei der digitalen transformation optimale gesch√§ftsprozesse und exzellente kundenkommunikation  wir sind der erfahrene und starke partner an ihrer seite optimieren sie ihre prozesse f√ºr die zukunft  mit unserer expertise als langj√§hriger partner f√ºhrender finanzdienstleister wir begleiten gesetzliche und √∂ffentliche kassen in die digitale transformation  vertrauen auch sie unserer expertise moderne kundenkommunikation √ºber alle kan√§le  vertrauen sie unserer ausgewiesenen kompetenz und erfahrung gesch√§ftsprozesse im saperpsystem f√ºr die digitale trans...   \n",
       "410  ausgestattet mit unserer hochentwickelten asr und ttstechnologie steuern sie von innovativer crmsoftware √ºber smart homes und factories das internet of things bis hin zu telefoniedialogsystemen in sicherheitsrelevanten anwendungen unsere ausgereiften semantischen tools finden nicht w√∂rter oder begriffe sondern bedeutungen hiermit analysieren wir ihre audio online und textdateien mit wirklich sinnvollen ergebnissen die weit √ºber keyword spotting new topic detection oder googeln hinausgehen und machen aus ihren big data smart data manche nennen es k√ºnstliche intelligenz unsere domainvoices werden genau auf ihr individuelles vokabular trainiert damit kommen wir ihren anspr√ºchen einer menschlichen aussprache n√§her als je zuvor kundenexklusive corporate voices transportieren nicht weniger als ihr modernes image ihre corporate identity in h√∂rbarer form quasi kurf√ºrstenanlage   w d heidelberg phone     fax     email webtext to speech eine nuance besser unsere k√ºnstlichen stimmen weisen ei...   \n",
       "\n",
       "     predicted_software  similarity_gis  similarity_ai  \n",
       "249                   1             0.0       0.081769  \n",
       "277                   1             0.0       0.055849  \n",
       "376                   1             0.0       0.045024  \n",
       "546                   1             0.0       0.034868  \n",
       "410                   1             0.0       0.033321  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_hit_ai = unlabelled_data[unlabelled_data[\"predicted_software\"] == 1].sort_values(by=[\"similarity_ai\"], ascending=False).head(5)\n",
    "top_hit_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"350\"\n",
       "            src=\"https://www.cpu-24-7.com/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x283aab183c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(IFrame(top_hit_ai[\"url\"].values[0], width=1200, height=350))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
